{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representaciones distribuidas\n",
    "\n",
    "Las representaciones distribuidas en el contexto del procesamiento del lenguaje natural (NLP) y el aprendizaje automático se refieren a una forma de representar palabras o entidades como vectores de características continuas en un espacio vectorial de alta dimensión. Esta metodología contrasta con las representaciones discretas o locales, como los métodos de bolsa de palabras o one-hot encoding, donde cada palabra se representa como un vector único en un espacio de dimensiones muy grandes, con un solo elemento igual a 1 (representando la presencia de la palabra) y el resto igual a 0.\n",
    "\n",
    "La idea clave detrás de las representaciones distribuidas es que las palabras se representan mediante patrones de características numéricas, de tal manera que las similitudes semánticas y sintácticas entre las palabras se reflejan en la cercanía de sus vectores correspondientes en el espacio vectorial. En otras palabras, palabras con significados o usos similares tendrán representaciones vectoriales similares.\n",
    "\n",
    "Las representaciones distribuidas han revolucionado la manera en que las máquinas entienden el lenguaje humano, permitiendo avances significativos en tareas de NLP como traducción automática, análisis de sentimientos, clasificación de texto, y muchas otras, gracias a su capacidad para capturar y utilizar la rica información semántica y sintáctica del lenguaje.\n",
    "Utilizan arquitecturas de redes neuronales para crear representaciones densas y de baja dimensión de palabras y textos. Pero antes de analizar estos métodos, debemos comprender algunos términos clave: \n",
    "\n",
    "  \n",
    "- Similitud distributiva: Ésta es la idea de que el significado de una palabra puede entenderse a partir del contexto en el que aparece. Esto también se conoce como connotación: el significado se define por el contexto. Esto se opone a la denotación: el significado literal de cualquier palabra. Por ejemplo: \" NLP rocks \". El significado literal de la palabra \"rocks\" es \"piedras\", pero por el contexto, se usa para referirse a algo bueno y de moda. \n",
    "\n",
    "- Hipótesis distributiva: En lingüística, esto plantea la hipótesis de que las palabras que ocurren en contextos similares tienen significados similares. Por ejemplo, las palabras inglesas \"dog\" y \"cat\" aparecen en contextos similares. Por tanto, según la hipótesis distributiva, debe haber una gran similitud entre los significados de estas dos palabras. Ahora, siguiendo con VSM, el significado de una palabra está representado por el vector. Por lo tanto, si dos palabras aparecen a menudo en un contexto similar, entonces sus vectores de representación correspondientes también deben estar cerca uno del otro. \n",
    "\n",
    "- Representación distributiva: Se refiere a esquemas de representación que se obtienen en base a la distribución de palabras del contexto en el que aparecen. Estos esquemas se basan en hipótesis distributivas. La propiedad distributiva se induce a partir del contexto (vecindad textual). Matemáticamente, los esquemas de representación distributiva utilizan vectores de alta dimensión para representar palabras. Estos vectores se obtienen a partir de una matriz de coocurrencia que captura la coocurrencia de palabra y contexto. La dimensión de esta matriz es igual al tamaño del vocabulario del corpus. Los cuatro esquemas que hemos visto hasta ahora (one-hot, bolsa de palabras, bolsa de n-gramas y TF-IDF) caen bajo el paraguas de la representación distributiva. \n",
    "\n",
    "- Representación distribuida: Este es un concepto relacionado. También se basa en la hipótesis distributiva. Como se analizó en el párrafo anterior, los vectores en representación distributiva son dispersos y de muy altas dimensiones. Esto los hace computacionalmente ineficientes y dificulta el aprendizaje. Para aliviar esto, los esquemas de representación distribuida comprimen significativamente la dimensionalidad. Esto da como resultado vectores que son compactos (es decir, de baja dimensión) y densos (es decir, casi sin ceros). El espacio vectorial resultante se conoce como representación distribuida. Todos los esquemas posteriores que analizaremos en esta clase son ejemplos de representación distribuida. \n",
    "\n",
    "- Embeddings: Para el conjunto de palabras en un corpus, el embedding es un mapeo entre el espacio vectorial proveniente de la representación distributiva y el espacio vectorial proveniente de la representación distribuida. \n",
    "\n",
    "- Semántica vectorial: Esto se refiere al conjunto de métodos de NLP que tienen como objetivo aprender las representaciones de palabras basadas en las propiedades distributivas de las palabras en un corpus grande. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Características Principales\n",
    "\n",
    "Veamos algunos características de estos métodos:\n",
    "\n",
    "- A diferencia de las representaciones locales, las distribuidas pueden capturar relaciones complejas entre palabras, como sinónimos, antónimos o términos que suelen aparecer en contextos similares.\n",
    "\n",
    "- Al representar palabras como vectores de tamaño fijo en un espacio continuo, se reduce la dimensionalidad del problema comparado con métodos de representación más simples pero de alta dimensionalidad, como el one-hot encoding.\n",
    "\n",
    "- Estos modelos pueden generalizar para entender palabras nuevas o raras a partir de sus componentes (por ejemplo, entender palabras compuestas a partir de los significados de sus partes).\n",
    "\n",
    "**Ejemplos y modelos**\n",
    "\n",
    "- Word2Vec: Probablemente el ejemplo más conocido de representaciones distribuidas. Word2Vec utiliza redes neuronales para aprender representaciones vectoriales de palabras a partir de grandes conjuntos de datos de texto. Ofrece dos arquitecturas principales: CBOW (Continuous Bag of Words) y Skip-gram, cada una diseñada para aprender representaciones que predigan palabras en función de sus contextos o viceversa.\n",
    "\n",
    "- GloVe (Global Vectors for Word Representation): Un modelo que aprende representaciones de palabras a partir de las estadísticas co-ocurrenciales de palabras en un corpus. La idea es que las relaciones semánticas entre palabras pueden ser capturadas observando qué tan frecuentemente aparecen juntas en un gran corpus.\n",
    "\n",
    "- Embeddings Contextuales: Modelos más recientes como ELMo, BERT y GPT ofrecen una evolución de las representaciones distribuidas, generando vectores de palabras que varían según el contexto en el que aparecen, lo que permite capturar usos y significados múltiples de una misma palabra dependiendo de la oración en la que se encuentre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings de palabras\n",
    "\n",
    "Los embeddings de palabras son representaciones vectoriales densas y de baja dimensión de palabras, diseñadas para capturar el significado semántico, sintáctico y relaciones entre ellas. A diferencia de las representaciones de texto más antiguas, como el one-hot encoding, que son dispersas (la mayoría de los valores son cero) y de alta dimensión, los embeddings de palabras se representan en un espacio vectorial continuo donde palabras con significados similares están ubicadas cercanamente en el espacio vectorial.\n",
    "\n",
    "**Características de los embeddings de palabras**\n",
    "\n",
    "- Cada palabra se representa como un vector denso, lo que significa que cada dimensión tiene un valor real, a diferencia de los vectores dispersos de otras técnicas de representación.\n",
    "\n",
    "- Los embeddings generalmente tienen un tamaño de dimensión fijo y relativamente pequeño (por ejemplo, 100, 200, 300 dimensiones) independientemente del tamaño del vocabulario.\n",
    "\n",
    "- Estos vectores intentan capturar el contexto y el significado de una palabra, no solo su presencia o ausencia. Palabras que se usan en contextos similares tendrán embeddings similares.\n",
    "\n",
    "- Pueden ayudar a los modelos de aprendizaje automático a generalizar mejor a palabras no vistas durante el entrenamiento, dado que las palabras con significados similares se mapean a puntos cercanos en el espacio vectorial.\n",
    "\n",
    "\n",
    "En 2013, un trabajo fundamental de Mikolov [Efficient Estimationof Word Representations in Vector Space](https://arxiv.org/abs/1301.3781) demostraron que su modelo de representación de palabras basado en una red neuronal conocido como `Word2vec`, basado en la `similitud distributiva`, puede capturar relaciones de analogía de palabras como: \n",
    "\n",
    "$$King - Man + Woman \\approx Queen$$\n",
    "\n",
    "Conceptualmente, Word2vec toma un gran corpus de texto como entrada y \"aprende\" a representar las palabras en un espacio vectorial común en función de los contextos en los que aparecen en el corpus.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embeddings de palabras pre-entrenadas\n",
    "\n",
    "El siguente es un ejemplo de cómo cargar embeddings de Word2vec previamente entrenadas y buscar las palabras más similares (clasificadas por similitud de coseno) a una palabra determinada. \n",
    "\n",
    "Tomemos un ejemplo de un modelo word2vec previamente entrenado y cómo podemos usarlo para buscar la mayoría de las palabras similares. Usaremos los embeddings de vectores de Google News. https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM\n",
    "\n",
    "Se pueden encontrar algunos otros modelos de embeddings de palabras previamente entrenados y detalles sobre los medios para acceder a ellos a través de gensim en: https://github.com/RaRe-Technologies/gensim-data\n",
    "\n",
    "El código que sigue cubre los pasos clave. Aquí encontramos las palabras que semánticamente son más similares a la palabra “beautiful”; la última línea devuelve el vector de embeddings de la palabra \" beautiful \":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /home/clara/anaconda3/lib/python3.7/site-packages (4.7.3)\n",
      "Requirement already satisfied: filelock in /home/clara/anaconda3/lib/python3.7/site-packages (from gdown) (3.9.0)\n",
      "Requirement already satisfied: requests[socks] in /home/clara/anaconda3/lib/python3.7/site-packages (from gdown) (2.28.1)\n",
      "Requirement already satisfied: six in /home/clara/anaconda3/lib/python3.7/site-packages (from gdown) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /home/clara/anaconda3/lib/python3.7/site-packages (from gdown) (4.64.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/clara/anaconda3/lib/python3.7/site-packages (from gdown) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/clara/anaconda3/lib/python3.7/site-packages (from beautifulsoup4->gdown) (2.3.2.post1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/clara/anaconda3/lib/python3.7/site-packages (from requests[socks]->gdown) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/clara/anaconda3/lib/python3.7/site-packages (from requests[socks]->gdown) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/clara/anaconda3/lib/python3.7/site-packages (from requests[socks]->gdown) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/clara/anaconda3/lib/python3.7/site-packages (from requests[socks]->gdown) (2022.12.7)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/clara/anaconda3/lib/python3.7/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "\u001b[33mDEPRECATION: swifter 1.0.7 has a non-standard dependency specifier ipywidgets>=7.0.0cloudpickle>=0.2.2. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of swifter or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM\n",
      "From (redirected): https://drive.google.com/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM&confirm=t&uuid=21699b2d-86ae-4413-8ac3-4e90599adf85\n",
      "To: /home/clara/Desktop/GoogleNews-vectors-negative300.bin.gz\n",
      "100%|██████████| 1.65G/1.65G [01:11<00:00, 23.0MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo descomprimido en GoogleNews-vectors-negative300.bin\n"
     ]
    }
   ],
   "source": [
    "import gdown\n",
    "import gzip\n",
    "import shutil\n",
    "\n",
    "# URL de Google Drive\n",
    "url = 'https://drive.google.com/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM'\n",
    "\n",
    "# Ruta donde se guardará el archivo comprimido descargado\n",
    "ruta_descarga = \"GoogleNews-vectors-negative300.bin.gz\"\n",
    "\n",
    "# Ruta del archivo descomprimido\n",
    "ruta_extraccion = \"GoogleNews-vectors-negative300.bin\"\n",
    "\n",
    "# Descargar el archivo usando gdown\n",
    "gdown.download(url, ruta_descarga, quiet=False)\n",
    "\n",
    "# Descomprimir el archivo   \n",
    "with gzip.open(ruta_descarga, 'rb') as f_in:\n",
    "    with open(ruta_extraccion, 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "print(f\"Archivo descomprimido en {ruta_extraccion}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "import psutil \n",
    "procesos = psutil.Process(os.getpid())\n",
    "from psutil import virtual_memory\n",
    "memoria = virtual_memory()\n",
    "\n",
    "import time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos algunos cálculos del uso de los datos descargados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memoria usada en GB antes de cargar el modelo: 0.16\n",
      "----------\n",
      "46.18 segundos para tomar\n",
      "----------\n",
      "Finalizacion de cargar  Word2Vec\n",
      "----------\n",
      "Memoria usada en GB despues de cargar el modelo: 4.29\n",
      "----------\n",
      "Aumento porcentual en el uso de memoria: 2669.03% \n",
      "----------\n",
      "Numero de palabras en el vocabulario:  3000000\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "pretrainedpath = ruta_extraccion\n",
    "\n",
    "#Se carga el modelo W2V. \n",
    "pre = procesos.memory_info().rss\n",
    "print(\"Memoria usada en GB antes de cargar el modelo: %0.2f\"%float(pre/(10**9))) \n",
    "print('-'*10)\n",
    "\n",
    "tiempo_inicio = time.time() \n",
    "ttl = memoria.total \n",
    "\n",
    "w2v_modelo = KeyedVectors.load_word2vec_format(pretrainedpath, binary=True) \n",
    "print(\"%0.2f segundos para tomar\"%float(time.time() - tiempo_inicio)) \n",
    "print('-'*10)\n",
    "\n",
    "print('Finalizacion de cargar  Word2Vec')\n",
    "print('-'*10)\n",
    "\n",
    "post = procesos.memory_info().rss\n",
    "print(\"Memoria usada en GB despues de cargar el modelo: {:.2f}\".format(float(post/(10**9))))\n",
    "print('-'*10)\n",
    "print(\"Aumento porcentual en el uso de memoria: {:.2f}% \".format(float((post/pre)*100))) \n",
    "print('-'*10)\n",
    "\n",
    "print(\"Numero de palabras en el vocabulario: \",len(w2v_modelo.index_to_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examinemos el modelo sabiendo cuáles son las palabras más similares para una palabra determinada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gorgeous', 0.8353003263473511),\n",
       " ('lovely', 0.8106936812400818),\n",
       " ('stunningly_beautiful', 0.7329413294792175),\n",
       " ('breathtakingly_beautiful', 0.7231340408325195),\n",
       " ('wonderful', 0.6854085922241211),\n",
       " ('fabulous', 0.6700063943862915),\n",
       " ('loveliest', 0.6612576842308044),\n",
       " ('prettiest', 0.6595001816749573),\n",
       " ('beatiful', 0.6593326330184937),\n",
       " ('magnificent', 0.6591402888298035)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_modelo.most_similar(\"beautiful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01831055,  0.05566406, -0.01153564,  0.07275391,  0.15136719,\n",
       "       -0.06176758,  0.20605469, -0.15332031, -0.05908203,  0.22851562,\n",
       "       -0.06445312, -0.22851562, -0.09472656, -0.03344727,  0.24707031,\n",
       "        0.05541992, -0.00921631,  0.1328125 , -0.15429688,  0.08105469,\n",
       "       -0.07373047,  0.24316406,  0.12353516, -0.09277344,  0.08203125,\n",
       "        0.06494141,  0.15722656,  0.11279297, -0.0612793 , -0.296875  ,\n",
       "       -0.13378906,  0.234375  ,  0.09765625,  0.17773438,  0.06689453,\n",
       "       -0.27539062,  0.06445312, -0.13867188, -0.08886719,  0.171875  ,\n",
       "        0.07861328, -0.10058594,  0.23925781,  0.03808594,  0.18652344,\n",
       "       -0.11279297,  0.22558594,  0.10986328, -0.11865234,  0.02026367,\n",
       "        0.11376953,  0.09570312,  0.29492188,  0.08251953, -0.05444336,\n",
       "       -0.0090332 , -0.0625    , -0.17578125, -0.08154297,  0.01062012,\n",
       "       -0.04736328, -0.08544922, -0.19042969, -0.30273438,  0.07617188,\n",
       "        0.125     , -0.05932617,  0.03833008, -0.03564453,  0.2421875 ,\n",
       "        0.36132812,  0.04760742,  0.00631714, -0.03088379, -0.13964844,\n",
       "        0.22558594, -0.06298828, -0.02636719,  0.1171875 ,  0.33398438,\n",
       "       -0.07666016, -0.06689453,  0.04150391, -0.15136719, -0.22460938,\n",
       "        0.03320312, -0.15332031,  0.07128906,  0.16992188,  0.11572266,\n",
       "       -0.13085938,  0.12451172, -0.20410156,  0.04736328, -0.296875  ,\n",
       "       -0.17480469,  0.00872803, -0.04638672,  0.10791016, -0.203125  ,\n",
       "       -0.27539062,  0.2734375 ,  0.02563477, -0.11035156,  0.0625    ,\n",
       "        0.1953125 ,  0.16015625, -0.13769531, -0.09863281, -0.1953125 ,\n",
       "       -0.22851562,  0.25390625,  0.00915527, -0.03857422,  0.3984375 ,\n",
       "       -0.1796875 ,  0.03833008, -0.24804688,  0.03515625,  0.03881836,\n",
       "        0.03442383, -0.04101562,  0.20214844, -0.03015137, -0.09619141,\n",
       "        0.11669922, -0.06738281,  0.0625    ,  0.10742188,  0.25585938,\n",
       "       -0.21777344,  0.05639648, -0.0065918 ,  0.16113281,  0.11865234,\n",
       "       -0.03088379, -0.11572266,  0.02685547,  0.03100586,  0.09863281,\n",
       "        0.05883789,  0.00634766,  0.11914062,  0.07324219, -0.01586914,\n",
       "        0.18457031,  0.05322266,  0.19824219, -0.22363281, -0.25195312,\n",
       "        0.15039062,  0.22753906,  0.05737305,  0.16992188, -0.22558594,\n",
       "        0.06494141,  0.11914062, -0.06640625, -0.10449219, -0.07226562,\n",
       "       -0.16992188,  0.0625    ,  0.14648438,  0.27148438, -0.02172852,\n",
       "       -0.12695312,  0.18457031, -0.27539062, -0.36523438, -0.03491211,\n",
       "       -0.18554688,  0.23828125, -0.13867188,  0.00296021,  0.04272461,\n",
       "        0.13867188,  0.12207031,  0.05957031, -0.22167969, -0.18945312,\n",
       "       -0.23242188, -0.28710938, -0.00866699, -0.16113281, -0.24316406,\n",
       "        0.05712891, -0.06982422,  0.00053406, -0.10302734, -0.13378906,\n",
       "       -0.16113281,  0.11621094,  0.31640625, -0.02697754, -0.01574707,\n",
       "        0.11425781, -0.04174805,  0.05908203,  0.02661133, -0.08642578,\n",
       "        0.140625  ,  0.09228516, -0.25195312, -0.31445312, -0.05688477,\n",
       "        0.01031494,  0.0234375 , -0.02331543, -0.08056641,  0.01269531,\n",
       "       -0.34179688,  0.17285156, -0.16015625,  0.07763672, -0.03088379,\n",
       "        0.11962891,  0.11767578,  0.20117188, -0.01940918,  0.02172852,\n",
       "        0.23046875,  0.28125   , -0.17675781,  0.02978516,  0.08740234,\n",
       "       -0.06176758,  0.00939941, -0.09277344, -0.203125  ,  0.13085938,\n",
       "       -0.13671875, -0.00500488, -0.04296875,  0.12988281,  0.3515625 ,\n",
       "        0.0402832 , -0.12988281, -0.03173828,  0.28515625,  0.18261719,\n",
       "        0.13867188, -0.16503906, -0.26171875, -0.04345703,  0.0100708 ,\n",
       "        0.08740234,  0.00421143, -0.1328125 , -0.17578125, -0.04321289,\n",
       "       -0.015625  ,  0.16894531,  0.25      ,  0.37109375,  0.19921875,\n",
       "       -0.36132812, -0.10302734, -0.20800781, -0.20117188, -0.01519775,\n",
       "       -0.12207031, -0.12011719, -0.07421875, -0.04345703,  0.14160156,\n",
       "        0.15527344, -0.03027344, -0.09326172, -0.04589844,  0.16796875,\n",
       "       -0.03027344,  0.09179688, -0.10058594,  0.20703125,  0.11376953,\n",
       "       -0.12402344,  0.04003906,  0.06933594, -0.34570312,  0.03881836,\n",
       "        0.16210938,  0.05761719, -0.12792969, -0.05810547,  0.03857422,\n",
       "       -0.11328125, -0.1953125 , -0.28125   , -0.13183594,  0.15722656,\n",
       "       -0.09765625,  0.09619141, -0.09960938, -0.00285339, -0.03637695,\n",
       "        0.15429688,  0.06152344, -0.34570312,  0.11083984,  0.03344727],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_modelo['beautiful']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Montreal', 0.784034013748169),\n",
       " ('Calgary', 0.7214041352272034),\n",
       " ('Ottawa', 0.7206088304519653),\n",
       " ('Edmonton', 0.7140310406684875),\n",
       " ('Winnipeg', 0.7064762711524963),\n",
       " ('Vancouver', 0.6859602928161621),\n",
       " ('Mississauga', 0.6640441417694092),\n",
       " ('Guelph', 0.6620159149169922),\n",
       " ('Saskatoon', 0.6398695707321167),\n",
       " ('Etobicoke', 0.6206150054931641)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_modelo.most_similar(\"Toronto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'practicaNLP' not present\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c2445f083019>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mw2v_modelo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'practicaNLP'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key_or_keys)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \"\"\"\n\u001b[1;32m    403\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_or_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_KEY_TYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_or_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey_or_keys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, key, norm)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \"\"\"\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_norms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_index\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Key '{key}' not present\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Key 'practicaNLP' not present\""
     ]
    }
   ],
   "source": [
    "w2v_modelo['practicaNLP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué pasa si busco una palabra que no está en este vocabulario?:\n",
    "`w2v_modelo['practicalnlp']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dos cosas a tener en cuenta al utilizar modelos previamente entrenados:\n",
    "\n",
    "* Los tokens/palabras siempre están en minúsculas. Si una palabra no está en el vocabulario, el modelo genera una excepción.\n",
    "* Por lo tanto, siempre es una buena idea encapsular esas declaraciones en bloques `try/except`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenando nuestros embeddings \n",
    "\n",
    "Ahora nos centraremos en entrenar nuestras propias embeddings de palabras. Para ello, veremos dos variantes arquitectónicas propuestas en el enfoque original de Word2vec. Las dos variantes son: \n",
    "\n",
    "* Bolsa continua de palabras (CBOW) \n",
    "\n",
    "* Skip-Gram \n",
    "\n",
    "Para utilizar los algoritmos CBOW y SkipGram en la práctica, hay varias implementaciones disponibles que nos abstraen los detalles matemáticos. Una de las implementaciones más utilizadas es [gensim](https://github.com/piskvorky/gensim). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CBOW\n",
    "\n",
    "El modelo Continuous Bag of Words (CBOW) es uno de los dos enfoques arquitectónicos propuestos por Mikolov  para aprender representaciones vectoriales de palabras, también conocidos como embeddings de palabras.\n",
    "\n",
    "Este modelo predice una palabra objetivo (la palabra central) a partir de un conjunto dado de palabras de contexto que la rodean en una frase o un párrafo. El \"contexto\" se refiere generalmente a las `n` palabras antes y después de la palabra objetivo en una ventana específica de tamaño `2n+1`, excluyendo la palabra objetivo.\n",
    "\n",
    "Por ejemplo, en la oración `el gato come pescado`, si queremos predecir la palabra `come` utilizando un contexto de tamaño 1, las palabras de contexto serían `[\"gato\", \"pescado\"]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al definir datos de entrenamiento, Genism word2vec requiere que se proporcione un formato de \"lista de listas\" para el entrenamiento donde cada documento esté contenido en una lista. Cada lista contiene listas de tokens de ese documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [['dog','bites','man'], [\"man\", \"bites\" ,\"dog\"],[\"dog\",\"eats\",\"meat\"],[\"man\", \"eats\",\"food\"]]\n",
    "\n",
    "#entrenando el modelo\n",
    "modelo_cbow = Word2Vec(corpus, min_count=1,sg=0) #usando la arquitectura CBOW para entrenamiento\n",
    "modelo_skipgram = Word2Vec(corpus, min_count=1,sg=1)#usando la arquitectura skipGram para entrenamiento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec<vocab=6, vector_size=100, alpha=0.025>\n"
     ]
    }
   ],
   "source": [
    "print(modelo_cbow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En CBOW, la tarea principal es construir un modelo de lenguaje que prediga correctamente la palabra central dadas las palabras de contexto en las que aparece esa palabra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-8.6196875e-03  3.6657380e-03  5.1898835e-03  5.7419371e-03\n",
      "  7.4669169e-03 -6.1676763e-03  1.1056137e-03  6.0472824e-03\n",
      " -2.8400517e-03 -6.1735227e-03 -4.1022300e-04 -8.3689503e-03\n",
      " -5.6000138e-03  7.1045374e-03  3.3525396e-03  7.2256685e-03\n",
      "  6.8002464e-03  7.5307419e-03 -3.7891555e-03 -5.6180713e-04\n",
      "  2.3483753e-03 -4.5190332e-03  8.3887316e-03 -9.8581649e-03\n",
      "  6.7646410e-03  2.9144168e-03 -4.9328329e-03  4.3981862e-03\n",
      " -1.7395759e-03  6.7113829e-03  9.9648498e-03 -4.3624449e-03\n",
      " -5.9933902e-04 -5.6956387e-03  3.8508223e-03  2.7866268e-03\n",
      "  6.8910765e-03  6.1010956e-03  9.5384959e-03  9.2734173e-03\n",
      "  7.8980681e-03 -6.9895051e-03 -9.1558648e-03 -3.5575390e-04\n",
      " -3.0998420e-03  7.8943158e-03  5.9385728e-03 -1.5456629e-03\n",
      "  1.5109634e-03  1.7900396e-03  7.8175711e-03 -9.5101884e-03\n",
      " -2.0553112e-04  3.4691954e-03 -9.3897345e-04  8.3817719e-03\n",
      "  9.0107825e-03  6.5365052e-03 -7.1162224e-04  7.7104042e-03\n",
      " -8.5343365e-03  3.2071066e-03 -4.6379971e-03 -5.0889566e-03\n",
      "  3.5896183e-03  5.3703380e-03  7.7695129e-03 -5.7665063e-03\n",
      "  7.4333595e-03  6.6254949e-03 -3.7098003e-03 -8.7456414e-03\n",
      "  5.4374672e-03  6.5097548e-03 -7.8755140e-04 -6.7098569e-03\n",
      " -7.0859264e-03 -2.4970602e-03  5.1432536e-03 -3.6652375e-03\n",
      " -9.3700597e-03  3.8267397e-03  4.8844791e-03 -6.4285635e-03\n",
      "  1.2085581e-03 -2.0748782e-03  2.4402141e-05 -9.8835090e-03\n",
      "  2.6920033e-03 -4.7501065e-03  1.0876465e-03 -1.5762257e-03\n",
      "  2.1966719e-03 -7.8815771e-03 -2.7171851e-03  2.6631975e-03\n",
      "  5.3466819e-03 -2.3915148e-03 -9.5100952e-03  4.5058774e-03]\n"
     ]
    }
   ],
   "source": [
    "# Acceder al vocabulario\n",
    "palabras = list(modelo_cbow.wv.index_to_key)\n",
    "\n",
    "# Acceder al vector para una palabra específica correctamente\n",
    "vector_dog=modelo_cbow.wv.get_vector('dog')\n",
    "# Otra manera válida pero menos explícita es modelo_cbow.wv['dog']\n",
    "# Completa\n",
    "print(vector_dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La similaridad entre eats y bites es: -0.013497107\n",
      "La similaridas entre eats y man es: -0.052354384\n"
     ]
    }
   ],
   "source": [
    "#Calculamos la similaridad\n",
    "print(\"La similaridad entre eats y bites es:\", modelo_cbow.wv.similarity('eats', 'bites'))\n",
    "print(\"La similaridas entre eats y man es:\", modelo_cbow.wv.similarity('eats', 'man'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('food', 0.13887983560562134),\n",
       " ('bites', 0.13149003684520721),\n",
       " ('eats', 0.06422409415245056),\n",
       " ('dog', 0.009391188621520996),\n",
       " ('man', -0.05987628176808357)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo_cbow.wv.most_similar('meat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec<vocab=6, vector_size=100, alpha=0.025>\n"
     ]
    }
   ],
   "source": [
    "# Guardando el modelo\n",
    "modelo_cbow.save('modelo_cbow.bin')\n",
    "\n",
    "# cargando el modelo\n",
    "nuevo_modelo_cbow = Word2Vec.load('modelo_cbow.bin')\n",
    "print(nuevo_modelo_cbow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SkipGram\n",
    "\n",
    "Continuous Bag of Words (CBOW) y Skip-gram  son dos arquitecturas del modelo Word2Vec desarrolladas por Mikolov  para generar representaciones vectoriales densas de palabras, conocidas como embeddings. Estos embeddings capturan relaciones semánticas y sintácticas entre palabras basadas en su co-ocurrencia en grandes corpus de texto. \n",
    "\n",
    "Ambas arquitecturas utilizan una red neuronal poco profunda para aprender estas representaciones, pero difieren en la forma en que están estructuradas y en cómo aprenden de los datos.\n",
    "\n",
    "La arquitectura Skip-gram predice las palabras de contexto (palabras circundantes) dada una palabra objetivo. Por ejemplo, si consideramos la frase `El rápido zorro marrón`, y nuestra palabra objetivo es `rápido`, con un tamaño de ventana de contexto de 2, Skip-gram intentaría predecir `El`, `zorro`, `marrón` a partir de `rápido`. Esto significa que para cada palabra objetivo en el corpus, se generan muestras de entrenamiento al emparejarla con las palabras de contexto dentro de una ventana específica alrededor de ella.\n",
    "\n",
    "Recuerda la arquitectura CBOW, por otro lado, hace lo opuesto: predice la palabra objetivo a partir de las palabras de contexto. Utilizando el mismo ejemplo anterior, CBOW tomaría `El`, `zorro`, `marrón` como entrada para predecir `rápido`. \n",
    "\n",
    "En esencia, CBOW promedia las palabras de contexto (o las suma, dependiendo de la implementación) para predecir la palabra en el centro de la ventana de contexto.\n",
    "\n",
    "A pesar de la disponibilidad de varias implementaciones listas para usar, todavía tenemos que tomar decisiones sobre varios hiperparámetros (es decir, las variables que deben configurarse antes de comenzar el proceso de entrenamiento). Veamos dos ejemplos. \n",
    "\n",
    "\n",
    "- Dimensionalidad de los vectores de palabras: como su nombre lo indica, esto decide el espacio de las embeddings aprendidas. Si bien no existe un número ideal, es común construir vectores de palabras con dimensiones en el rango de 50 a 500 y evaluarlos en la tarea para la que los estamos usando para elegir la mejor opción. \n",
    "\n",
    "- Ventana contextual: Qué tan largo o corto es el contexto que buscamos para aprender la representación vectorial. \n",
    "\n",
    "También hay otras opciones que hacemos, como usar CBOW o SkipGram para aprender las embeddings. Estas elecciones son más un arte que una ciencia en este momento, y hay mucha investigación en curso sobre métodos para elegir los hiperparámetros correctos. \n",
    "\n",
    "Usando paquetes como gensim, es bastante sencillo desde el punto de vista del código implementar Word2vec. \n",
    "\n",
    "El siguiente código muestra cómo entrenar nuestro propio modelo Word2vec usando un corpus llamado `common_texts` que está disponible en gensim. Suponiendo que tiene el corpus para su dominio, siguiendo este fragmento de código obtendrá rápidamente sus propias embeddings: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec<vocab=6, vector_size=100, alpha=0.025>\n",
      "['man', 'dog', 'eats', 'bites', 'food', 'meat']\n",
      "[-8.6196875e-03  3.6657380e-03  5.1898835e-03  5.7419371e-03\n",
      "  7.4669169e-03 -6.1676763e-03  1.1056137e-03  6.0472824e-03\n",
      " -2.8400517e-03 -6.1735227e-03 -4.1022300e-04 -8.3689503e-03\n",
      " -5.6000138e-03  7.1045374e-03  3.3525396e-03  7.2256685e-03\n",
      "  6.8002464e-03  7.5307419e-03 -3.7891555e-03 -5.6180713e-04\n",
      "  2.3483753e-03 -4.5190332e-03  8.3887316e-03 -9.8581649e-03\n",
      "  6.7646410e-03  2.9144168e-03 -4.9328329e-03  4.3981862e-03\n",
      " -1.7395759e-03  6.7113829e-03  9.9648498e-03 -4.3624449e-03\n",
      " -5.9933902e-04 -5.6956387e-03  3.8508223e-03  2.7866268e-03\n",
      "  6.8910765e-03  6.1010956e-03  9.5384959e-03  9.2734173e-03\n",
      "  7.8980681e-03 -6.9895051e-03 -9.1558648e-03 -3.5575390e-04\n",
      " -3.0998420e-03  7.8943158e-03  5.9385728e-03 -1.5456629e-03\n",
      "  1.5109634e-03  1.7900396e-03  7.8175711e-03 -9.5101884e-03\n",
      " -2.0553112e-04  3.4691954e-03 -9.3897345e-04  8.3817719e-03\n",
      "  9.0107825e-03  6.5365052e-03 -7.1162224e-04  7.7104042e-03\n",
      " -8.5343365e-03  3.2071066e-03 -4.6379971e-03 -5.0889566e-03\n",
      "  3.5896183e-03  5.3703380e-03  7.7695129e-03 -5.7665063e-03\n",
      "  7.4333595e-03  6.6254949e-03 -3.7098003e-03 -8.7456414e-03\n",
      "  5.4374672e-03  6.5097548e-03 -7.8755140e-04 -6.7098569e-03\n",
      " -7.0859264e-03 -2.4970602e-03  5.1432536e-03 -3.6652375e-03\n",
      " -9.3700597e-03  3.8267397e-03  4.8844791e-03 -6.4285635e-03\n",
      "  1.2085581e-03 -2.0748782e-03  2.4402141e-05 -9.8835090e-03\n",
      "  2.6920033e-03 -4.7501065e-03  1.0876465e-03 -1.5762257e-03\n",
      "  2.1966719e-03 -7.8815771e-03 -2.7171851e-03  2.6631975e-03\n",
      "  5.3466819e-03 -2.3915148e-03 -9.5100952e-03  4.5058774e-03]\n"
     ]
    }
   ],
   "source": [
    "print(modelo_skipgram)\n",
    "palabras = list(modelo_skipgram.wv.index_to_key)\n",
    "print(palabras)\n",
    "\n",
    "vector_dog = modelo_skipgram.wv['dog']\n",
    "\n",
    "# Opción 2: Usar el método `.get_vector()`\n",
    "vector_dog = modelo_skipgram.wv.get_vector('dog')\n",
    "\n",
    "print(vector_dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similaridad entre eats y  bites: -0.013518808\n",
      "Similaridad entre eats y  man: -0.05234511\n"
     ]
    }
   ],
   "source": [
    "#Calculamos la similaridad\n",
    "print(\"Similaridad entre eats y  bites:\",modelo_skipgram.wv.similarity('eats', 'bites'))\n",
    "print(\"Similaridad entre eats y  man:\",modelo_skipgram.wv.similarity('eats', 'man'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('eps', 0.2914133071899414), ('trees', 0.055417995899915695), ('minors', 0.04264770820736885), ('survey', -0.02176349051296711)]\n",
      "[ 0.01631949  0.00189972  0.03474648  0.0021784   0.09621626  0.05062076\n",
      " -0.08919987 -0.07043611  0.00901718  0.06394394]\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "modelo_w =Word2Vec(common_texts, vector_size=10, window=5, min_count=1, workers=4)\n",
    "modelo_w.save(\"modelo_ws.w2v\")\n",
    "\n",
    "print(modelo_w.wv.most_similar(\"computer\", topn=4))\n",
    "print(modelo_w.wv.get_vector('computer'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicios**\n",
    "\n",
    "1.Experimenta con otras palabras y guarda el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Entrena un modelo Word2Vec en modo CBOW con un corpus de texto de tu elección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "# Ejemplo de corpus: lista de frases\n",
    "corpus = [\n",
    "    \"Gensim es una biblioteca de modelado de temas de Python.\",\n",
    "    \"Gensim incluye implementaciones de Word2Vec, Doc2Vec, y otros modelos.\",\n",
    "    \"Los embeddings de palabras son útiles para tareas de procesamiento de lenguaje natural.\"\n",
    "]\n",
    "\n",
    "# Preprocesamiento simple y tokenización\n",
    "corpus_tokenizado = [simple_preprocess(doc) for doc in corpus]\n",
    "\n",
    "# Entrenar un modelo Word2Vec en modo CBOW (sg=0)\n",
    "modelo_cbow = Word2Vec(sentences=corpus_tokenizado, vector_size=100, window=5, min_count=1, workers=4, sg=0)\n",
    "\n",
    "# Guardar el modelo\n",
    "modelo_cbow.save(\"modelo_cbow.word2vec\")\n",
    "\n",
    "# Imprimir las palabras más similares a 'gensim'\n",
    "print(modelo_cbow.wv.most_similar('gensim'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 . Entrena un modelo Word2Vec en modo Skip-gram con el mismo corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando el mismo corpus_tokenizado del ejercicio anterior\n",
    "\n",
    "# Entrenar un modelo Word2Vec en modo Skip-gram (sg=1)\n",
    "modelo_skipgram = Word2Vec(sentences=corpus_tokenizado, vector_size=100, window=5, min_count=1, workers=4, sg=1)\n",
    "\n",
    "# Guardar el modelo\n",
    "modelo_skipgram.save(\"modelo_skipgram.word2vec\")\n",
    "\n",
    "# Imprimir las palabras más similares a 'word2vec'\n",
    "print(modelo_skipgram.wv.most_similar('word2vec'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 . Carga un modelo de embeddings preentrenado y utiliza para encontrar palabras similares. Debes descargar un conjunto de embeddings preentrenados como Google News vectors o cualquier otro de tu elección y proporcionar la ruta correcta al cargarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Cargar embeddings preentrenados (reemplazar 'path_to_embeddings' con la ruta real)\n",
    "# Asegúrate de tener el archivo .bin o el formato correcto del modelo que estás cargando\n",
    "modelo_preentrenado = KeyedVectors.load_word2vec_format('path_to_embeddings.bin', binary=True)\n",
    "\n",
    "# Imprimir las palabras más similares a 'king'\n",
    "print(modelo_preentrenado.most_similar('king'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tus respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Existe alguna forma de utilizar embeddings de palabras para obtener representaciones de características para unidades de texto más grandes? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente código muestra cómo obtener la representación vectorial de texto promediando vectores de palabras usando la biblioteca spaCy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "%time \n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "doc1 = nlp(\"Canada is a large country\")\n",
    "#print(doc[0].vector) #vector para 'Canada', la primera palabra en el texto\n",
    "print(doc1.vector)# Vector promedio para toda la oracion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué sucede cuando doy una oración con palabras extrañas e intento obtener su vector de palabras en Spacy?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp = nlp('practicalnlp is a newword')\n",
    "#temp[0].vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectores de documentos\n",
    "\n",
    "Doc2vec nos permite aprender directamente las representaciones de textos de longitud arbitraria (frases, oraciones, párrafos y documentos), teniendo en cuenta el contexto de las palabras del texto.\n",
    "\n",
    "Esto es similar a Word2vec en términos de su arquitectura general, excepto que, además de los vectores de palabras, también aprende un \"vector de párrafo\" que aprende una representación del texto completo (es decir, con palabras en contexto). Cuando se aprende con un corpus grande de muchos textos, los vectores de párrafo son únicos para un texto determinado (donde \"texto\" puede significar cualquier fragmento de texto de longitud arbitraria), mientras que los vectores de palabras se compartirán en todos los textos.  \n",
    "\n",
    "\n",
    "Hay dos arquitecturas del modelo Doc2Vec, que es una extensión de Word2Vec diseñada para generar representaciones vectoriales no solo para palabras sino también para piezas de texto más grandes como oraciones, párrafos y documentos. Estas representaciones vectoriales son útiles para muchas tareas de procesamiento del lenguaje natural, como la clasificación de textos y la búsqueda semántica. Aquí están las dos arquitecturas: \n",
    "\n",
    "**Memoria distribuida (DM)**: \n",
    "\n",
    "En el modelo DM de Doc2Vec, cada palabra y el párrafo (o documento) entero tienen su propio vector de aprendizaje único en una \"Paragraph Matrix\" y en una \"Word Matrix\", respectivamente. \n",
    "\n",
    "Durante el entrenamiento, el modelo intenta predecir la siguiente palabra en un contexto dada una ventana de palabras y el vector único del párrafo/documento. \n",
    "\n",
    "Los vectores de las palabras y del párrafo se pueden promediar o concatenar antes de enviarlos a una capa de clasificador, que intenta predecir la palabra siguiente. \n",
    "\n",
    "El objetivo es que al final del entrenamiento, el vector del párrafo capture la esencia del texto, lo que hace posible usar este vector para tareas de clasificación o comparación de similitud. \n",
    "\n",
    "**Bolsa de palabras distribuidas (DBOW)**: \n",
    "\n",
    "El modelo DBOW funciona de manera inversa al DM. Ignora el contexto de las palabras y, en su lugar, fuerza al modelo a predecir las palabras en un párrafo/documento dada solo la identificación del párrafo (es decir, su vector único). \n",
    "\n",
    "No hay una capa de promedio o concatenación; el modelo directamente predice las palabras a partir del vector del párrafo. \n",
    "\n",
    "Al igual que en el modelo DM, el vector del párrafo se entrena para representar el contenido completo del párrafo/documento. \n",
    "\n",
    "DBOW es eficaz para grandes conjuntos de datos donde la semántica puede ser capturada incluso sin el orden exacto de las palabras. \n",
    "\n",
    "Ambos métodos son útiles para aprender representaciones vectoriales que reflejan el significado de los párrafos o documentos, aunque capturan diferentes aspectos de los datos: DM toma en cuenta el orden de las palabras, mientras que DBOW se centra en la ocurrencia de las palabras. Estos vectores resultantes pueden ser utilizados en diversas tareas, tales como agrupación de documentos, clasificación y búsqueda por similitud semántica. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /home/clara/anaconda3/lib/python3.7/site-packages (from en-core-web-sm==3.7.1) (3.7.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/clara/anaconda3/lib/python3.7/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/clara/anaconda3/lib/python3.7/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/clara/anaconda3/lib/python3.7/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.7)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/clara/anaconda3/lib/python3.7/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.6)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/clara/anaconda3/lib/python3.7/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.6)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /home/clara/anaconda3/lib/python3.7/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/clara/anaconda3/lib/python3.7/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.10.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/clara/anaconda3/lib/python3.7/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.4)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/clara/anaconda3/lib/python3.7/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /home/clara/anaconda3/lib/python3.7/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /home/clara/anaconda3/lib/python3.7/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/clara/anaconda3/lib/python3.7/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/clara/anaconda3/lib/python3.7/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.64.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/clara/anaconda3/lib/python3.7/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.28.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/clara/anaconda3/lib/python3.7/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.9.2)\n",
      "Requirement already satisfied: jinja2 in /home/clara/anaconda3/lib/python3.7/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.11.3)\n",
      "Requirement already satisfied: setuptools in /home/clara/anaconda3/lib/python3.7/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/clara/anaconda3/lib/python3.7/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (22.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/clara/anaconda3/lib/python3.7/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.5.0,>=3.7.4.1 in /home/clara/anaconda3/lib/python3.7/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.1.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/clara/anaconda3/lib/python3.7/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.20.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/clara/anaconda3/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.11.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/clara/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/clara/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/clara/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/clara/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2022.12.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/clara/anaconda3/lib/python3.7/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/clara/anaconda3/lib/python3.7/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/clara/anaconda3/lib/python3.7/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /home/clara/anaconda3/lib/python3.7/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/clara/anaconda3/lib/python3.7/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.1)\n",
      "Requirement already satisfied: importlib-metadata in /home/clara/anaconda3/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.11.3)\n",
      "\u001b[33mDEPRECATION: swifter 1.0.7 has a non-standard dependency specifier ipywidgets>=7.0.0cloudpickle>=0.2.2. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of swifter or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos que cada frase de los documentos corresponde a un documento independiente y iteramos sobre cada documento e iniciar una instancia de NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documento despues del preprocesamiento: ['dog bites man', 'man bites dog', 'dog eats meat', 'man eats food']\n",
      "------------------------------\n",
      "Vector promedio de 'dog bites man'\n",
      " [-0.4645846  -0.8704827  -0.8797126   0.5601492   0.21902908 -0.13645978\n",
      "  0.44058624  1.827665    0.16126743 -0.18749698  0.7041428  -0.3796244\n",
      " -0.37697935 -0.81970304 -0.6127835   0.70265275 -0.6612517  -0.19193421\n",
      "  0.472255    0.08093234 -0.27145305 -0.01265816 -0.5408774  -0.34591904\n",
      "  0.48944393  0.2113028   0.01028296  0.63884515  0.22854471 -0.12605749\n",
      " -0.03728535 -0.0155863   0.0091201   0.36559033 -0.84108526 -0.43349206\n",
      "  0.26574     0.47921833  0.09730821 -0.16394196 -0.07839262 -0.03694795\n",
      " -0.4529426  -0.08880541 -0.38659295 -0.15151542  0.35047397  0.8556697\n",
      " -0.18897362 -0.16618592  0.10892     0.00644581  0.43828678 -0.4840901\n",
      " -0.01481809  0.0661923   1.2289283  -0.6374825   0.44061872 -0.01362112\n",
      " -0.40318158 -0.42995203 -0.1989394  -0.5829177  -0.31625822 -0.1792578\n",
      "  0.17091231  0.3254232  -0.03885905  0.49847683  0.4659768   0.5765772\n",
      "  1.4753227  -0.8773132   0.20510907  0.09932882 -0.21316928 -0.00922679\n",
      " -0.08790653 -0.9831574   0.07044614 -0.15759344 -0.40787318 -0.37125924\n",
      " -0.38353133  0.173752   -0.44787577 -0.28161666 -0.9059532   0.43466672\n",
      " -0.30246073  0.68414766  1.4254211   0.6507121  -0.3187259   0.27555943]\n",
      "\n",
      "dog [-8.6835611e-01 -1.4402475e+00  5.8450431e-02  4.3280989e-01\n",
      " -6.7178190e-02  3.7222600e-01  7.3643947e-01  1.8121853e+00\n",
      " -1.6749349e-01 -1.8459061e-01  4.7201008e-01 -3.9696854e-01\n",
      " -1.2453122e+00 -9.5441830e-01 -4.5812142e-01 -1.8084943e-01\n",
      " -1.0747354e+00 -1.2153941e+00 -6.8441677e-01 -2.9416841e-01\n",
      "  4.6376830e-01  4.5101517e-01  5.3776264e-01 -2.0192602e-01\n",
      "  3.2549477e-01  4.0339231e-01  4.2194438e-01  1.3879567e+00\n",
      "  8.1691206e-01 -1.2877837e-01  5.1112026e-02 -9.1927087e-01\n",
      "  9.2327070e-01  2.1118914e-01 -7.8291154e-01 -2.2929186e-01\n",
      "  2.8055575e-01 -8.4280038e-01  8.2651436e-02  1.6201413e+00\n",
      "  2.2326231e-02  5.8424294e-01 -1.0934174e-03  8.2272381e-01\n",
      " -8.4002674e-02 -4.1348818e-01 -4.7699785e-01  1.6973743e+00\n",
      "  2.2830951e-01  5.8092885e-03 -4.4765761e-01 -3.6683702e-01\n",
      "  1.0276493e+00 -9.2888659e-01 -1.7414860e-01  1.5785727e-01\n",
      "  6.7340213e-01 -9.6637082e-01  6.5350741e-02 -8.7674117e-01\n",
      " -8.2756358e-01 -4.9598500e-01 -5.5277789e-01 -1.6462290e-01\n",
      " -3.3623224e-01 -3.2565141e-01  1.1318043e-01  4.1256914e-01\n",
      "  6.0981727e-01 -2.1142617e-01  1.2131807e+00  6.7787409e-01\n",
      "  1.4212610e+00 -7.5987828e-01  6.6678411e-01  2.8687829e-01\n",
      " -5.0114274e-01 -3.5809463e-01  6.8374121e-01 -9.0728760e-01\n",
      "  3.0375317e-02 -7.1259695e-01 -7.7439690e-01 -7.1905088e-01\n",
      "  1.2676744e-01  3.7779945e-01  3.2650113e-01 -4.2369142e-01\n",
      " -1.9922161e+00  7.0590496e-01 -3.7211823e-01  4.8597395e-01\n",
      "  1.7030704e+00  1.0449063e+00 -6.4605147e-01  1.0147259e-02]\n",
      "\n",
      "bites [ 0.53755313  0.852277   -0.8949803   1.2423465   0.94026667 -0.7416104\n",
      "  0.05073753  1.451275    0.92292047  0.03149134  1.490675    0.07525548\n",
      "  0.17841452 -1.6167331  -0.60676163  1.548026   -0.4695462   0.7274193\n",
      "  0.57484555  0.05330259 -0.70534736 -1.1735033  -0.95847416  0.7337005\n",
      "  0.39098215  0.44368902 -0.02519719  0.27466154  0.14353213 -0.16914499\n",
      " -0.05738655 -0.17008151 -0.91384244  0.34115493 -0.6759577  -0.87085646\n",
      "  0.2665004   0.94627917 -0.13716471 -0.73002726  0.5632796  -0.32905644\n",
      " -0.5536657  -0.48851186 -1.000622   -0.42325592  0.7508462   0.69349444\n",
      " -0.5441062  -0.39150763  0.2499543  -0.7346902   0.1036345  -0.12442705\n",
      " -0.6335743   0.09631918  1.9570526  -1.5125366   0.22674674  0.86738324\n",
      " -0.18096226 -0.828695   -0.4237176  -0.9488997  -0.25783128 -0.3759007\n",
      "  0.10121705  0.5426603   0.22159871  0.6327126   0.16381446 -0.00851429\n",
      "  1.0157387  -0.7447468  -0.21131605 -0.03225647  0.6909169   0.41212958\n",
      " -1.0398555  -0.4099226   0.26442638  0.3447963  -0.4403171  -0.2033163\n",
      " -0.94579756 -0.09565462 -1.1066966  -0.42651564 -0.22926237 -0.00921005\n",
      "  0.936686    1.2199364   1.022955    0.17317119 -1.4837575  -0.23223975]\n",
      "\n",
      "man [-1.0629508  -2.0234776  -1.8026079   0.00529119 -0.21600121 -0.03999497\n",
      "  0.5345817   2.2195349  -0.2716247  -0.4093917   0.1497433  -0.8171601\n",
      " -0.06404036  0.11204225 -0.77346754  0.7407819  -0.43947345 -0.08782779\n",
      "  1.5263362   0.48366284 -0.5727801   0.6845136  -1.2019207  -1.5695317\n",
      "  0.75185496 -0.21317291 -0.36589828  0.25391716 -0.27481008 -0.0802491\n",
      " -0.10558154  1.0425935   0.01793203  0.5444269  -1.0643867  -0.2003279\n",
      "  0.25016382  1.3341762   0.3464379  -1.3819399  -0.82078373 -0.36603034\n",
      " -0.80406874 -0.6006282  -0.07515401  0.3821978   0.7775735   0.17614043\n",
      " -0.2511242  -0.11285938  0.5244633   1.1208646   0.18357652 -0.3989566\n",
      "  0.76326865 -0.05559954  1.0563302   0.56646     1.0297587  -0.03150542\n",
      " -0.20101888  0.03482386  0.3796773  -0.63523054 -0.3547112   0.16377869\n",
      "  0.29833943  0.02104028 -0.94799316  1.074144    0.02093536  1.0603718\n",
      "  1.9889681  -1.1273146   0.15985918  0.04336467 -0.829282   -0.08171533\n",
      "  0.09239468 -1.632262   -0.08346328 -0.10497969 -0.00890557 -0.19141057\n",
      " -0.33156392  0.23911111 -0.56343186  0.00535718 -0.4963813   0.6073052\n",
      " -1.4719499   0.34653282  1.550238    0.73405886  1.1736312   1.0487708 ]\n",
      "------------------------------\n",
      "Vector promedio de 'man bites dog'\n",
      " [-0.7306302  -1.0671597  -0.504978    0.6526523   0.02486174 -0.35224175\n",
      "  0.3144424   1.9733596   0.01980591  0.05146671  0.8803007  -0.71425146\n",
      " -0.36052355 -0.88362575 -0.6089213   0.60436827 -0.01241982 -0.41080728\n",
      "  0.337613    0.20771568  0.13066618  0.19761837 -1.0279742  -0.2484603\n",
      "  0.28615952  0.7462438   0.05431575  1.0756313  -0.18376379  0.08834196\n",
      " -0.12316593 -0.10065377  0.38223544  0.66054696 -0.71566224 -0.28583226\n",
      "  0.23971479  0.4178386   0.13060233  0.10314232  0.04413782 -0.64384216\n",
      " -0.0577405   0.12155527 -0.6347292  -0.15715884  0.5355564   0.72926456\n",
      " -0.08269465 -0.4376113   0.050405    0.17615493  0.4861479  -0.3358182\n",
      " -0.4225259   0.03832766  1.5562605  -0.60945845  0.793082    0.09892774\n",
      " -0.51906174 -0.4502592   0.11988672 -0.6918175  -0.27107933 -0.11782792\n",
      "  0.4024855   0.45168194 -0.12758824  0.68019205  0.4078699   0.37755358\n",
      "  1.3182739  -1.1492985   0.42953113  0.23179893 -0.6461878  -0.52119994\n",
      " -0.04883574 -1.1255795   0.06273472 -0.0439299  -0.88457876 -0.38104793\n",
      "  0.3340594   0.00634654 -0.13174765  0.01101581 -1.3615656   0.45404568\n",
      " -0.25349805 -0.10483932  0.87395304  0.8247059  -0.2433002   0.12653935]\n",
      "\n",
      "man [-8.79114211e-01 -1.38556910e+00  3.19381595e-01  4.59639907e-01\n",
      " -3.21569055e-01 -6.29504621e-01  6.17790580e-01  2.88375235e+00\n",
      " -9.21689689e-01  6.46661445e-02  1.66365337e+00 -5.57702661e-01\n",
      " -9.57001090e-01 -6.19923294e-01 -5.14829099e-01 -1.73290461e-01\n",
      "  1.64335608e-01 -3.13723177e-01  2.81348050e-01 -2.55565733e-01\n",
      "  5.92893660e-01  1.26296744e-01  3.97069931e-01 -3.41926724e-01\n",
      "  1.35711476e-01  5.27022660e-01 -2.85105139e-01  2.22202063e+00\n",
      " -5.17624766e-02 -2.32311189e-02  9.22622979e-02 -4.83765185e-01\n",
      "  5.83833098e-01  7.42794573e-02 -1.19426441e+00 -3.72811019e-01\n",
      "  5.89658320e-02 -7.63673902e-01  5.09983540e-01  1.88390720e+00\n",
      " -2.01835752e-01 -5.27875662e-01 -3.74071896e-02  1.09075153e+00\n",
      " -7.09591508e-01 -4.32738066e-02  2.49876469e-01  1.81237745e+00\n",
      "  8.43178034e-02 -5.96174359e-01 -5.98514676e-01 -4.17072833e-01\n",
      "  1.06952441e+00 -3.26088101e-01 -4.15209472e-01  4.32526350e-01\n",
      "  1.47315156e+00 -9.66146827e-01  7.07711399e-01 -7.15251505e-01\n",
      " -7.10802734e-01  2.73908675e-03  6.35291159e-01 -5.66123426e-01\n",
      "  3.34241748e-01  5.70932925e-02 -5.76020479e-02  1.15317404e-01\n",
      " -3.13811779e-01 -8.18491340e-01  3.49318683e-01  5.68446696e-01\n",
      "  1.02969790e+00 -1.60924149e+00  7.09241152e-01  3.12634230e-01\n",
      " -1.05531597e+00 -7.86078334e-01  5.36619544e-01 -8.94367993e-01\n",
      "  6.78417027e-01 -5.61675668e-01 -1.30546856e+00 -8.96046638e-01\n",
      "  1.08656079e-01  6.64486587e-02  8.23870450e-02  4.66708958e-01\n",
      " -1.36702204e+00  1.70287204e+00 -6.29697442e-01  3.43287557e-01\n",
      "  1.07563519e+00  9.66083407e-01 -8.87329698e-01 -4.91206408e-01]\n",
      "\n",
      "bites [ 0.11117512  0.3655398  -0.41415235  1.3579305   0.67336094 -0.9465215\n",
      " -0.30141082  1.3651143   0.541902    0.58480465  1.2693224  -0.67354184\n",
      " -0.18257338 -2.0160131  -0.34482828  1.3469375   0.15619858  0.11462109\n",
      " -0.31840405  0.02689874 -0.19621184 -1.3130386  -1.5442747   0.7636169\n",
      "  0.20449218  0.8986758   0.3466279   0.24440527  0.04614523 -0.17169458\n",
      " -0.2578014  -0.4456606  -0.8661112   0.9908319  -0.75112236 -0.45723325\n",
      "  0.42527446  1.1132225   0.0108398  -0.62450397  1.0705798  -0.7776155\n",
      " -0.36939514 -0.31100485 -1.0686505  -0.5970974   1.3680726   0.73840904\n",
      "  0.0885337  -0.71311384  0.4491818  -1.1052628  -0.03858595 -0.00896126\n",
      " -1.3267804   0.17298532  1.8134769  -0.71581584  0.7410678   1.5184786\n",
      " -0.35128438 -0.6647494   0.12939492 -0.98883384 -0.3406179   0.16827661\n",
      "  0.79645675  1.2623906  -0.54138404  1.4250855   0.5213168  -0.31939182\n",
      "  1.0426782  -0.91932744 -0.3330908   0.06353998 -0.06305815 -0.39997518\n",
      " -0.86889374 -1.1371212   0.13932961  0.37341222 -0.43285784 -0.34568593\n",
      " -0.10556346 -0.17738272 -1.0196235   0.11249241 -0.77042603 -0.40188974\n",
      "  1.2064812   0.36012524  0.30549473  0.8824089  -0.9713631  -0.39967683]\n",
      "\n",
      "dog [-1.4239516  -2.1814497  -1.4201632   0.14038646 -0.27720666  0.5193009\n",
      "  0.62694746  1.6712122   0.4392054  -0.49507067 -0.2920736  -0.91150975\n",
      "  0.05800384 -0.01494072 -0.96710646  0.6394578  -0.35779363 -1.0333198\n",
      "  1.0498949   0.851814   -0.00468326  1.7795969  -1.936718   -1.1670711\n",
      "  0.5182749   0.813033    0.10142449  0.7604679  -0.5456741   0.45995158\n",
      " -0.20395868  0.6274645   1.4289844   0.91652954 -0.20159993 -0.02745247\n",
      "  0.23490404  0.90396726 -0.12901637 -0.94997627 -0.73633057 -0.6260353\n",
      "  0.23358083 -0.41508085 -0.12594573  0.1688947  -0.01127997 -0.36299282\n",
      " -0.42093545 -0.00354561  0.30054787  2.0508003   0.42750522 -0.6724053\n",
      "  0.4744121  -0.49052867  1.3821528  -0.14641266  0.93046683 -0.5064439\n",
      " -0.4950981  -0.6887674  -0.40502596 -0.52049536 -0.8068619  -0.57885367\n",
      "  0.46860176 -0.0226622   0.4724311   1.433982    0.35297415  0.8836059\n",
      "  1.8824452  -0.91932654  0.9124431   0.31922254 -0.82018924 -0.37754637\n",
      "  0.185767   -1.3452493  -0.62954247  0.05647373 -0.9154099   0.09858885\n",
      "  0.9990856   0.12997368  0.54199356 -0.5461539  -1.9472488   0.06115489\n",
      " -1.3372779  -1.0179307   1.240729    0.62562525  1.1287923   1.2705013 ]\n",
      "------------------------------\n",
      "Vector promedio de 'dog eats meat'\n",
      " [-5.28143823e-01 -3.25464100e-01  3.72720927e-01  1.38100743e-01\n",
      " -1.41998276e-01  1.36182532e-01  1.00769794e+00  7.65502036e-01\n",
      "  6.65335178e-01 -2.78228130e-02  1.20318782e+00 -5.80319285e-01\n",
      " -9.22352001e-02 -6.07282460e-01  6.98678866e-02  2.47129783e-01\n",
      " -1.08566284e-01 -7.02527344e-01  2.66367227e-01  8.20308030e-01\n",
      " -9.70045745e-04 -3.31810117e-02 -1.22109926e+00 -3.77586991e-01\n",
      " -2.99743384e-01  5.49807549e-02  1.59115985e-01  1.37501585e+00\n",
      "  2.51957446e-01 -4.42793518e-01 -4.00887460e-01 -7.84086660e-02\n",
      "  3.35148163e-02  6.96318224e-02 -2.89102405e-01 -5.16775310e-01\n",
      " -1.01231933e-01  5.75358272e-01  3.43978815e-02  4.87464257e-02\n",
      "  6.24290884e-01  8.46515130e-03 -1.54015765e-01  1.51789010e-01\n",
      " -2.54198015e-01  1.53095827e-01 -1.27211809e-02  4.41033393e-01\n",
      "  4.51310277e-01 -4.95597839e-01 -3.43186140e-01 -2.98842102e-01\n",
      " -7.00786039e-02 -1.01728857e+00 -3.07770163e-01 -3.35108429e-01\n",
      "  3.88634354e-01 -3.83926004e-01 -4.69403952e-01  1.37675062e-01\n",
      "  2.45471239e-01  1.02620862e-01 -3.42203617e-01 -1.33137703e-02\n",
      "  6.14527285e-01 -2.20828637e-01 -1.65407538e-01 -1.81448355e-01\n",
      "  5.58797657e-01 -7.43770078e-02  3.99267823e-01  3.52573007e-01\n",
      "  1.02211237e+00 -3.85470659e-01 -9.20898095e-02 -1.84297130e-01\n",
      " -1.58681065e-01 -9.03255045e-01  1.03285946e-01 -1.15096855e+00\n",
      " -1.29709840e-01 -6.22247644e-02 -1.14429438e+00 -2.83837765e-01\n",
      "  9.09470558e-01  3.94834012e-01 -3.39352697e-01 -3.99675995e-01\n",
      " -6.70747757e-01  4.37409610e-01 -4.32595700e-01 -7.64422640e-02\n",
      "  6.95876896e-01  9.46226895e-01  3.45851183e-01  4.35208946e-01]\n",
      "\n",
      "dog [-1.0812949  -1.4307283   0.75221944  0.1712297   0.32177237  0.86005676\n",
      "  2.455635    1.346254   -0.09764092 -0.10778825  1.0484095  -0.94255984\n",
      " -0.6078259  -1.0490514  -0.5148936   0.45206374  0.43303132 -1.9615302\n",
      " -0.19738638  0.60159266  0.23741609  0.40716016 -0.36675307 -0.52062356\n",
      " -0.18169594  0.00556335  0.698676    1.8285468   0.42993015 -0.22435495\n",
      "  0.3385879  -1.3478445   1.0007404  -0.3818196  -0.8815308  -0.50092095\n",
      " -0.6030464   0.00396429 -0.65100765  1.7863722  -0.7132627  -0.38242656\n",
      "  0.10295442  0.9382783  -0.23424536  0.35401046  0.23344898  2.4129367\n",
      "  0.42005834  0.21459201 -0.25282592 -0.14887214  0.5238811  -0.9334421\n",
      "  0.17501083 -0.10541132  1.3329642  -1.1134646  -0.629055   -0.5565627\n",
      " -0.23847196 -0.52220356 -0.34234834 -0.2589562   0.22176215 -0.2713639\n",
      " -0.23087232 -0.01566558  0.98733795 -0.8318432   1.4004161   0.58804107\n",
      "  1.5626721  -0.97197914  0.05485786 -0.32219744 -0.10335097 -0.6646154\n",
      "  0.6692598  -1.6064699  -0.16225582  0.478828   -1.9106634  -0.8438724\n",
      " -0.19903296  0.5365102  -0.3102207  -1.102248   -1.8248603   0.07783419\n",
      " -0.74953085  0.2550239   1.7526369   0.17954019  0.07371992  1.1604346 ]\n",
      "\n",
      "eats [ 0.0421649   1.2653307   0.17378092  0.50767255 -1.0490422  -0.83302766\n",
      " -0.09663557 -0.13786055  1.0112994   0.4288267   2.4037488   0.25147\n",
      "  0.06019558 -1.1608033   0.10221952  0.30856392 -1.2557421   0.60147023\n",
      "  0.2386646   0.975688   -0.5915628  -1.2459583  -1.7676948   0.3097359\n",
      " -0.56041443 -0.6948842  -0.02296631  1.7154744  -0.07688862 -1.4475666\n",
      " -1.0816417   0.8648304  -0.7474811   0.39002168  0.43739045 -1.4360206\n",
      " -0.24660905  0.44019842  1.426893   -0.89165574  2.7853148   0.19570567\n",
      " -0.02530357 -0.46089375  0.2866099   0.03676188  1.310079   -0.38099283\n",
      "  1.1943154  -1.0843642  -0.6878987  -0.7726438  -0.8047862  -0.7496981\n",
      " -0.60453105 -0.2149057   0.09721962 -0.9057743  -0.6679503   0.9331264\n",
      "  0.07658947  0.93356735 -0.01161969  1.3947039   1.2018478  -0.01519735\n",
      " -0.06471393  0.6517881   0.7649658   1.0650358  -0.39588892 -0.01363389\n",
      "  0.37344274 -0.5166705  -0.06238467  0.13389055  0.37360227 -1.1396333\n",
      " -0.53609604 -0.98302084 -0.5472114   0.01786244 -0.970139   -0.06351209\n",
      "  1.5542035  -0.08930358 -0.93528473  0.71561736  0.08632542 -0.3436088\n",
      "  0.00525133 -0.3754957  -0.52525043  0.78954136 -0.03681129 -0.16560942]\n",
      "\n",
      "meat [-0.54530156 -0.8109947   0.1921624  -0.26460004  0.30127507  0.38151848\n",
      "  0.66409445  1.0881127   1.0823472  -0.40450686  0.15740526 -1.049868\n",
      "  0.27092472  0.3880071   0.62227774 -0.01923832  0.4970119  -0.7475221\n",
      "  0.75782347  0.88364345  0.35123658  0.73925513 -1.5288501  -0.92187333\n",
      " -0.15711975  0.85426307 -0.1983617   0.5810266   0.40283084  0.3435411\n",
      " -0.45960853  0.2477881  -0.15271485  0.20069338 -0.42316687  0.3866158\n",
      "  0.54595965  1.2819121  -0.6726917  -0.74847716 -0.19917925  0.21211635\n",
      " -0.5396981  -0.02201754 -0.8149586   0.06851512 -1.5816915  -0.7088436\n",
      " -0.26044297 -0.61702126 -0.08883385  0.0249896   0.07066932 -1.3687252\n",
      " -0.49379033 -0.68500835 -0.26428062  0.867461   -0.11120656  0.03646153\n",
      "  0.89829624 -0.1035012  -0.6726428  -1.175689    0.41997194 -0.37592465\n",
      " -0.2006364  -1.1804676  -0.07591073 -0.45632365  0.19327627  0.48331186\n",
      "  1.1302223   0.33223763 -0.26874262 -0.3645845  -0.7462945  -0.90551656\n",
      "  0.1766941  -0.8634149   0.3203377  -0.68336475 -0.5520809   0.05587125\n",
      "  1.3732411   0.7372953   0.2274474  -0.8123975  -0.27370822  1.5780034\n",
      " -0.55350757 -0.10885499  0.8602443   1.8695993   1.0006449   0.31080168]\n",
      "------------------------------\n",
      "Vector promedio de 'man eats food'\n",
      " [-0.5684238  -0.57287353  0.19061713 -0.02727501 -0.24726157 -0.47077575\n",
      "  0.67504615  0.91850376  0.46914983 -0.07541139  0.91001034 -0.6528694\n",
      "  0.20814113 -0.38525295  0.10724044  0.03721748  0.17622823 -0.42577264\n",
      "  0.84705025  0.4656135   0.2602125   0.13333614 -1.1832274  -0.3927336\n",
      " -0.3033259   0.05664682  0.02361459  1.1074073   0.0887716  -0.0993073\n",
      " -0.4287416   0.2351296   0.32357863 -0.1330789  -0.16306825 -0.42505345\n",
      "  0.03771551  0.6059893  -0.06135686  0.2674165   0.6370724  -0.11721343\n",
      "  0.07362372  0.281109   -0.447256    0.2777288   1.0692546   0.1829685\n",
      "  0.50409704 -0.32215205 -0.35159683 -0.12734115  0.29992318 -0.7535948\n",
      " -0.69702697 -0.3220543   0.71279544 -0.6150772   0.3298061   0.09947077\n",
      "  0.35389647 -0.2101698   0.26364794  0.3044763   0.3669416   0.09189647\n",
      " -0.44488588 -0.07889545  0.09186279 -0.02534238  0.0748578   0.07496563\n",
      "  0.87882304 -0.61746305 -0.18207853 -0.63431126 -0.19095246 -0.96059865\n",
      " -0.25158307 -0.8883353   0.07001067  0.04558152 -1.1473408  -0.8225753\n",
      "  0.08435123  0.15004471 -0.6038995   0.03660116 -0.69724756  0.95125127\n",
      " -0.68453044 -0.33696684  0.8739075   0.8438082   0.31379613  0.09725066]\n",
      "\n",
      "man [-0.7988444  -1.4189857   0.9587015   0.04842679 -0.13589221  0.13747323\n",
      "  2.1833463   2.2473629  -0.73056865 -0.4312911   2.074099   -0.5347986\n",
      " -0.113251   -0.6253557  -0.7677721  -0.20840454  1.2359262  -0.93447363\n",
      "  0.58791256  0.37700996  0.10563266 -0.03780547  0.01084305 -0.69158447\n",
      " -0.327804   -0.36715114 -0.02280542  1.747695    0.08014286  0.03233461\n",
      " -0.2784183  -0.06315391  0.6737462  -0.76864254 -1.2385308  -0.40180743\n",
      " -0.27125663  0.509653   -0.22441149  1.3312155  -1.3187828  -0.8340686\n",
      " -0.17655846  0.9881312  -0.8814026   0.3751557   0.9586714   2.4071546\n",
      "  0.41480535  0.42890483 -0.38265696 -0.25923443  0.3427679  -0.58612144\n",
      "  0.00641102  0.18200076  1.78459    -0.79376805  0.3263105  -0.3355506\n",
      " -0.08808893 -0.2797944   0.7338706  -0.47263372  0.5778024   0.29370302\n",
      " -0.5332607   0.08911547  0.41310832 -1.2725976   0.60949516  0.31898355\n",
      "  1.0445324  -1.3473339  -0.23375963 -0.6386354  -0.67730457 -0.78202903\n",
      "  0.1632284  -1.4732294   0.43231028  0.37187138 -1.4738096  -1.2937756\n",
      " -0.4854685   0.4704315  -0.7328727  -0.31353337 -1.0763397   0.7877184\n",
      " -1.2149078   0.57856494  1.163865    0.3926732  -0.3896406   0.63898563]\n",
      "\n",
      "eats [ 0.38699633  0.50218546 -0.1272017   0.12091185 -0.65172863 -1.0742174\n",
      " -0.5509342  -0.08040962  1.1873336   0.4689651   2.0373406   0.45032954\n",
      "  0.30590257 -1.0698978   0.54105484  0.3051741  -0.60722595  0.21979716\n",
      "  0.38876718  0.6405079  -0.26909178 -1.0225244  -1.4554276   0.4382489\n",
      " -0.3273911  -0.3911556   0.1099323   1.5800714   0.0929265  -1.1309092\n",
      " -1.0196956   0.75952804 -0.49086675  0.53936774  0.7879438  -0.69383824\n",
      " -0.31486553 -0.02596419  1.1034305  -1.0809706   2.576222    0.13817848\n",
      " -0.04756972 -0.8489025   0.4191138  -0.03645128  2.4032261  -0.9694729\n",
      "  1.1656398  -0.8138087  -0.75375473 -0.6546073  -0.8417248  -0.36461145\n",
      " -0.9081819  -0.35844362  0.08773941 -0.963043   -0.31266832  0.9028579\n",
      "  0.18334828  0.6470555  -0.00511706  0.9354669   0.88712376  0.05933802\n",
      " -0.33614513  0.8295213   0.21527968  1.522846   -0.5511629  -0.00322598\n",
      "  0.33593017 -0.3213934  -0.51905227 -0.08449636  0.16215335 -0.9613761\n",
      " -0.6350308  -0.7936935  -0.3519017   0.2689688  -0.69806397 -0.41445756\n",
      "  0.32774743  0.01505351 -1.1463544   0.41129428  0.1194514  -0.32158822\n",
      "  0.17465729 -0.9239396  -0.4182821   0.75396293  0.34239227  0.09298391]\n",
      "\n",
      "food [-1.2934234  -0.8018203  -0.25964844 -0.25116366  0.04583613 -0.47558305\n",
      "  0.39272618  0.5885579   0.95068455 -0.26390818 -1.3814087  -1.8741391\n",
      "  0.43177179  0.5394947   0.54843855  0.01488286 -0.10001552 -0.5626414\n",
      "  1.5644711   0.3793227   0.9440966   1.4603382  -2.1050978  -0.92486525\n",
      " -0.25478256  0.9282472  -0.01628311 -0.00554436  0.09324545  0.80065274\n",
      "  0.01188914  0.00901467  0.7878564  -0.1699619  -0.03861776 -0.1795147\n",
      "  0.6992687   1.3342791  -1.0630896   0.5520047   0.65377796  0.34424984\n",
      "  0.44499937  0.7040983  -0.87947917  0.49448198 -0.15413366 -0.8887762\n",
      " -0.06815395 -0.58155227  0.08162123  0.5318183   1.3987265  -1.3100514\n",
      " -1.1893101  -0.78972006  0.26605672 -0.08842063  0.9757761  -0.26889497\n",
      "  0.96643007 -0.99777055  0.06219023  0.45059568 -0.36410144 -0.07735163\n",
      " -0.46525186 -1.1553231  -0.35279962 -0.3262756   0.16624114 -0.09086069\n",
      "  1.2560065  -0.18366176  0.20657635 -1.179802   -0.05770619 -1.1383908\n",
      " -0.28294683 -0.39808297  0.12962344 -0.5040956  -1.2701486  -0.75949275\n",
      "  0.41077477 -0.03535089  0.06752875  0.01204257 -1.1348544   2.3876235\n",
      " -1.0133406  -0.6655259   1.8761396   1.3847885   0.9886367  -0.44021755]\n"
     ]
    }
   ],
   "source": [
    "documentos = [\"Dog bites man.\", \"Man bites dog.\", \"Dog eats meat.\", \"Man eats food.\"]\n",
    "docs_procesados = [doc.lower().replace(\".\",\"\") for doc in documentos]\n",
    "docs_procesados\n",
    "\n",
    "print(\"Documento despues del preprocesamiento:\",docs_procesados)\n",
    "\n",
    "for doc in docs_procesados:\n",
    "    doc_nlp = nlp(doc)\n",
    "    \n",
    "    print(\"-\"*30)\n",
    "    print(\"Vector promedio de '{}'\\n\".format(doc),doc_nlp.vector)\n",
    "    for token in doc_nlp:\n",
    "        print()\n",
    "        print(token.text,token.vector)# esto da el texto de cada palabra en el doc y sus valores respectivos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Ejercicio \n",
    "\n",
    "Entrena modelos Doc2Vec utilizando ambas arquitecturas, DM y DBOW, y compara su desempeño en una tarea de similitud de documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "# Preparación de datos: Tagging de cada documento en el corpus\n",
    "documentos = [TaggedDocument(doc, [i]) for i, doc in enumerate(corpus)]\n",
    "\n",
    "# DM\n",
    "modelo_dm = Doc2Vec(documents=documentos, vector_size=100, window=5, min_count=1, dm=1)\n",
    "modelo_dm.save(\"modelo_dm.doc2vec\")\n",
    "\n",
    "# DBOW\n",
    "modelo_dbow = Doc2Vec(documents=documentos, vector_size=100, window=5, min_count=1, dm=0)\n",
    "modelo_dbow.save(\"modelo_dbow.doc2vec\")\n",
    "\n",
    "# Escoge un documento y compara los documentos más similares desde ambos modelos\n",
    "doc_id = 0  # Asumiendo que quieres comprobar el primer documento del corpus\n",
    "print(\"DM Similar:\", modelo_dm.dv.most_similar([modelo_dm[doc_id]]))\n",
    "print(\"DBOW Similar:\", modelo_dbow.dv.most_similar([modelo_dbow[doc_id]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2vec usando gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/clara/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "from pprint import pprint\n",
    "import nltk\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentos = [\"Dog bites man.\", \n",
    "              \"Man bites dog.\", \n",
    "              \"Dog eats meat.\", \n",
    "              \"Man eats food.\"]\n",
    "documentos_etiquetados = [TaggedDocument(words=word_tokenize(word.lower()), tags=[str(i)]) for i, word in enumerate(documentos)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['dog', 'bites', 'man', '.'], tags=['0']),\n",
       " TaggedDocument(words=['man', 'bites', 'dog', '.'], tags=['1']),\n",
       " TaggedDocument(words=['dog', 'eats', 'meat', '.'], tags=['2']),\n",
       " TaggedDocument(words=['man', 'eats', 'food', '.'], tags=['3'])]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documentos_etiquetados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicando el modelo dbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_dbow = Doc2Vec(documentos_etiquetados, vector_size=20, min_count=1, epochs=2, dm=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.02416298 -0.0083937   0.02430472  0.00869157  0.00923718  0.00445012\n",
      " -0.01764159  0.0198998  -0.0186847   0.01969382 -0.01684111  0.01198323\n",
      " -0.0099582   0.01369533 -0.01277319  0.01277904 -0.01906677  0.01643007\n",
      " -0.00434805 -0.01253452]\n"
     ]
    }
   ],
   "source": [
    "print(modelo_dbow.infer_vector(['man', 'food', 'eats']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 0.39641645550727844),\n",
       " ('meat', 0.06596561521291733),\n",
       " ('man', 0.06166548281908035),\n",
       " ('dog', -0.014377479441463947),\n",
       " ('bites', -0.15920130908489227),\n",
       " ('eats', -0.18240399658679962)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo_dbow.wv.most_similar(\"food\", topn=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.11861518"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo_dbow.wv.n_similarity([\"man\"],[\"dog\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trabajando con el modelo DM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.11861518"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo_dm = Doc2Vec(documentos_etiquetados, min_count=1, vector_size=20, epochs=2, dm=1)\n",
    "modelo_dm.infer_vector([\"man\", \"eats\", \"food\"])\n",
    "modelo_dm.wv.most_similar(\"dog\", topn=5)\n",
    "modelo_dm.wv.n_similarity([\"man\"],[\"dog\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué pasa cuando comparamos palabras que no estan el vocabulario?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo_dm.wv.n_similarity([\"covid\"],[\"man\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
