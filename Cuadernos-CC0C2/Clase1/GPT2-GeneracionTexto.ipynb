{"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"_spBCI-ctejR"},"source":["### Generación de texto \n","\n","En este cuaderno, implementamos el modelo Transformer-XL de generación de texto utilizando PyTorch-Transformers: [Hugging Face](https://huggingface.co/).\n","Una de las caracteristicas de esta biblioteca es:\n","\n","* Modelos pre-entrenados: Proporciona modelos pre-entrenados de arquitecturas de NLP de última generación y pesos pre-entrenados para varias variaciones de estos modelos.\n","* Preprocesamiento y API de fine-tuning: PyTorch-Transformers no se detiene en pesos pre-entrenados. También proporciona una API simple para realizar todos los pasos de preprocesamiento y ajuste necesarios para estos modelos. \n","* Scripts de uso: también viene con scripts para ejecutar estos modelos y conjuntos de datos de referencia  como SQUAD 2.0 (Stanford Question Answering Dataset) y GLUE(General Language Understanding Evaluation). Al utilizar PyTorch-Transformers, se puede ejecutar directamente el modelo con estos conjuntos de datos y evaluar el rendimiento.\n","* Multilingüe: PyTorch-Transformers tiene soporte multilingüe. Esto se debe a que algunos de los modelos ya funcionan bien para varios lenguajes.\n","* Compatibilidad con TensorFlow: se puede importar checkpoints de TensorFlow como modelos en PyTorch\n","* Investigación: hay un campo de estudio creciente relacionado con la investigación del funcionamiento interno de transformadores a gran escala como BERT-"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ir0oyKcdthbG"},"source":["Usamos un modelo BERT preentrenado para este cuaderno."]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":349},"colab_type":"code","executionInfo":{"elapsed":3648,"status":"ok","timestamp":1573530123607,"user":{"displayName":"Cesar Lara Avila","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCxZ8yvpNAsodiP-pTL1tI8G7ck99_IB0_OjqEP=s64","userId":"17468538242674266126"},"user_tz":300},"id":"Sz7pP9zTuVrv","outputId":"2fa402db-8250-4c52-cbc1-e1f3d8b521f8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pytorch-pretrained-bert in /home/clara/anaconda3/lib/python3.7/site-packages (0.6.2)\n","Requirement already satisfied: tqdm in /home/clara/anaconda3/lib/python3.7/site-packages (from pytorch-pretrained-bert) (4.64.1)\n","Requirement already satisfied: regex in /home/clara/anaconda3/lib/python3.7/site-packages (from pytorch-pretrained-bert) (2022.7.9)\n","Requirement already satisfied: boto3 in /home/clara/anaconda3/lib/python3.7/site-packages (from pytorch-pretrained-bert) (1.9.243)\n","Requirement already satisfied: torch>=0.4.1 in /home/clara/anaconda3/lib/python3.7/site-packages (from pytorch-pretrained-bert) (1.10.2)\n","Requirement already satisfied: requests in /home/clara/anaconda3/lib/python3.7/site-packages (from pytorch-pretrained-bert) (2.28.1)\n","Requirement already satisfied: numpy in /home/clara/anaconda3/lib/python3.7/site-packages (from pytorch-pretrained-bert) (1.21.5)\n","Requirement already satisfied: typing_extensions in /home/clara/anaconda3/lib/python3.7/site-packages (from torch>=0.4.1->pytorch-pretrained-bert) (4.4.0)\n","Requirement already satisfied: botocore<1.13.0,>=1.12.243 in /home/clara/anaconda3/lib/python3.7/site-packages (from boto3->pytorch-pretrained-bert) (1.12.243)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/clara/anaconda3/lib/python3.7/site-packages (from boto3->pytorch-pretrained-bert) (0.9.4)\n","Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /home/clara/anaconda3/lib/python3.7/site-packages (from boto3->pytorch-pretrained-bert) (0.2.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/clara/anaconda3/lib/python3.7/site-packages (from requests->pytorch-pretrained-bert) (1.25.11)\n","Requirement already satisfied: certifi>=2017.4.17 in /home/clara/anaconda3/lib/python3.7/site-packages (from requests->pytorch-pretrained-bert) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /home/clara/anaconda3/lib/python3.7/site-packages (from requests->pytorch-pretrained-bert) (3.4)\n","Requirement already satisfied: charset-normalizer<3,>=2 in /home/clara/anaconda3/lib/python3.7/site-packages (from requests->pytorch-pretrained-bert) (2.0.4)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /home/clara/anaconda3/lib/python3.7/site-packages (from botocore<1.13.0,>=1.12.243->boto3->pytorch-pretrained-bert) (0.15.2)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/clara/anaconda3/lib/python3.7/site-packages (from botocore<1.13.0,>=1.12.243->boto3->pytorch-pretrained-bert) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /home/clara/anaconda3/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.13.0,>=1.12.243->boto3->pytorch-pretrained-bert) (1.16.0)\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"]}],"source":["!pip install pytorch-pretrained-bert"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"colab_type":"code","executionInfo":{"elapsed":4080,"status":"ok","timestamp":1573530124055,"user":{"displayName":"Cesar Lara Avila","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCxZ8yvpNAsodiP-pTL1tI8G7ck99_IB0_OjqEP=s64","userId":"17468538242674266126"},"user_tz":300},"id":"NZDee5cctguy","outputId":"a17ec6f3-77ad-4bb3-fe02-458c5a1d8003"},"outputs":[{"name":"stdout","output_type":"stream","text":["numpy: 1.21.5\n","torch: 1.10.2\n","pytorch_pretrained_bert: 0.6.2\n"]}],"source":["from functools import partial\n","from tqdm import trange\n","import torch\n","import torch.nn.functional as F\n","import numpy as np\n","import pytorch_pretrained_bert\n","from pytorch_pretrained_bert import GPT2LMHeadModel, GPT2Tokenizer\n","for mod in (np, torch, pytorch_pretrained_bert):\n","    print(f'{mod.__name__}: {mod.__version__}')"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"hhyFtNQ7utLO"},"source":["### Contruyamos el modelo  GPT2\n","\n","OpenAI creó el modelo de lenguaje llamado GPT-2. GPT-2 es un modelo de lenguaje generativo basado en transformers que se entrenó en 40 GB de texto de Internet.\n","\n","Al ser entrenado de manera no supervisada, simplemente aprende a predecir una secuencia de tokens más probables (es decir, palabras) que siguen un mensaje determinado, en función de los patrones que aprendió a reconocer a través de su entrenamiento.\n"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"colab_type":"code","executionInfo":{"elapsed":8239,"status":"ok","timestamp":1573530128229,"user":{"displayName":"Cesar Lara Avila","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCxZ8yvpNAsodiP-pTL1tI8G7ck99_IB0_OjqEP=s64","userId":"17468538242674266126"},"user_tz":300},"id":"d2MxJnRIuDdj","outputId":"8b77f601-99ee-4792-ad28-4cc2923b1271"},"outputs":[{"data":{"text/plain":["GPT2LMHeadModel(\n","  (transformer): GPT2Model(\n","    (wte): Embedding(50257, 768)\n","    (wpe): Embedding(1024, 768)\n","    (h): ModuleList(\n","      (0): Block(\n","        (ln_1): BertLayerNorm()\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","        )\n","        (ln_2): BertLayerNorm()\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","        )\n","      )\n","      (1): Block(\n","        (ln_1): BertLayerNorm()\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","        )\n","        (ln_2): BertLayerNorm()\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","        )\n","      )\n","      (2): Block(\n","        (ln_1): BertLayerNorm()\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","        )\n","        (ln_2): BertLayerNorm()\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","        )\n","      )\n","      (3): Block(\n","        (ln_1): BertLayerNorm()\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","        )\n","        (ln_2): BertLayerNorm()\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","        )\n","      )\n","      (4): Block(\n","        (ln_1): BertLayerNorm()\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","        )\n","        (ln_2): BertLayerNorm()\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","        )\n","      )\n","      (5): Block(\n","        (ln_1): BertLayerNorm()\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","        )\n","        (ln_2): BertLayerNorm()\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","        )\n","      )\n","      (6): Block(\n","        (ln_1): BertLayerNorm()\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","        )\n","        (ln_2): BertLayerNorm()\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","        )\n","      )\n","      (7): Block(\n","        (ln_1): BertLayerNorm()\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","        )\n","        (ln_2): BertLayerNorm()\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","        )\n","      )\n","      (8): Block(\n","        (ln_1): BertLayerNorm()\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","        )\n","        (ln_2): BertLayerNorm()\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","        )\n","      )\n","      (9): Block(\n","        (ln_1): BertLayerNorm()\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","        )\n","        (ln_2): BertLayerNorm()\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","        )\n","      )\n","      (10): Block(\n","        (ln_1): BertLayerNorm()\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","        )\n","        (ln_2): BertLayerNorm()\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","        )\n","      )\n","      (11): Block(\n","        (ln_1): BertLayerNorm()\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","        )\n","        (ln_2): BertLayerNorm()\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","        )\n","      )\n","    )\n","    (ln_f): BertLayerNorm()\n","  )\n","  (lm_head): GPT2LMHead(\n","    (decoder): Linear(in_features=768, out_features=50257, bias=False)\n","  )\n",")"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["seed = 0\n","np.random.seed(seed)\n","torch.random.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","nombre_modelo = 'gpt2'\n","enc = GPT2Tokenizer.from_pretrained('gpt2')\n","\n","modelo = GPT2LMHeadModel.from_pretrained(nombre_modelo)\n","modelo.to(device)\n","modelo.eval()"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"tzH5UXaPPgzD"},"source":["Eliminamos los warnings de python y realizamos una prueba del funcionamiento del modelo."]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{},"colab_type":"code","id":"F3SB00NSqRe7"},"outputs":[],"source":["import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","linea = \"Proof\"\n","tokens_tensor = torch.tensor(enc.encode(linea)).reshape(1, -1)\n","predicciones, _ = modelo(tokens_tensor)\n","tam_vocab = predicciones.shape[-1]\n","assert tam_vocab == 50257"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"colab_type":"code","executionInfo":{"elapsed":8223,"status":"ok","timestamp":1573530128235,"user":{"displayName":"Cesar Lara Avila","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCxZ8yvpNAsodiP-pTL1tI8G7ck99_IB0_OjqEP=s64","userId":"17468538242674266126"},"user_tz":300},"id":"JainBH3iql6_","outputId":"927232b5-38ff-4e96-a35e-f69bf4b81045"},"outputs":[{"data":{"text/plain":["(torch.Size([1, 1, 50257]), torch.Size([1, 1]))"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["predicciones.shape, tokens_tensor.shape"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"tM6Lik2XrPoV"},"source":["### Un ejemplo"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"colab_type":"code","executionInfo":{"elapsed":9421,"status":"ok","timestamp":1573530129446,"user":{"displayName":"Cesar Lara Avila","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCxZ8yvpNAsodiP-pTL1tI8G7ck99_IB0_OjqEP=s64","userId":"17468538242674266126"},"user_tz":300},"id":"wYEtNoKNrNbt","outputId":"c478c8a7-d5f7-4b56-e4e8-5f604d268570"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cars were invented in 1789 by Thomas Jefferson's brother William Jefferson (1787-1809),\n"]}],"source":["seed = 0\n","prompt = \"Cars were invented in\"\n","max_predicciones = 16\n","top_k = 40\n","\n","np.random.seed(seed)\n","torch.random.manual_seed(seed)\n","context_tokens = enc.encode(prompt)\n","context_tensor = torch.tensor(context_tokens, dtype=torch.long).reshape(1, -1)\n","\n","prev = context_tensor\n","salida = context_tensor.clone()\n","past = None\n","for i in range(max_predicciones):\n","    predicciones, past = modelo(prev, past=past)\n","    context_size = prev.shape[1]\n","    assert predicciones.shape == (1, context_size, tam_vocab)\n","    \n","    last_prediction = predicciones[:, -1, :]\n","    topk = torch.topk(last_prediction, 10)   \n","    log_probs = F.softmax(topk.values, dim=-1)  # softmax among the top-k\n","    rand_idx_in_topk = torch.multinomial(log_probs, num_samples=1)\n","    predicted_index = topk.indices[0][rand_idx_in_topk]      \n","    \n","    prev = torch.tensor([[ predicted_index ]])\n","    salida = torch.cat((salida, prev), dim=-1)\n","    \n","print(enc.decode(salida[0].tolist()))"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ef1gqf8IrmzS"},"source":["Construyamos un modelo de finalización de oraciones usando GPT-2. Intentaremos predecir la siguiente palabra en la oración: what is the fastest car in the _________\n","\n","Ejemplo desde: [https://www.analyticsvidhya.com/blog/2019/07/pytorch-transformers-nlp-python/](https://www.analyticsvidhya.com/blog/2019/07/pytorch-transformers-nlp-python/)\n","\n","\n"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"colab_type":"code","executionInfo":{"elapsed":12791,"status":"ok","timestamp":1573530132828,"user":{"displayName":"Cesar Lara Avila","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCxZ8yvpNAsodiP-pTL1tI8G7ck99_IB0_OjqEP=s64","userId":"17468538242674266126"},"user_tz":300},"id":"1LsghkdyrZxf","outputId":"dfb53e28-8968-47b9-8e48-e402b6ce280d"},"outputs":[{"name":"stdout","output_type":"stream","text":["What is the fastest car in the world\n"]}],"source":["texto = \"What is the fastest car in the\"\n","indexed_tokens = enc.encode(texto)\n","\n","tokens_tensor = torch.tensor([indexed_tokens])\n","modelo = GPT2LMHeadModel.from_pretrained('gpt2')\n","modelo.eval()\n","\n","# predicciones de tokens\n","with torch.no_grad():\n","  salidas = modelo(tokens_tensor)\n","  predicciones = salidas[0]\n","\n","predicted_index = torch.argmax(predicciones[0, -1, :]).item()\n","predicted_text = enc.decode(indexed_tokens + [predicted_index])\n","\n","# Predecimos la palabra predicha\n","print(predicted_text)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"VDzvW6M6s5hQ"},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"GPT2-GeneracionTexto.ipynb","provenance":[{"file_id":"1cyvnD0uzCs1LmjXB-LmGJFvDauLFdbPI","timestamp":1573523958225}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"}},"nbformat":4,"nbformat_minor":0}
