{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retropropagación\n",
    "\n",
    "\n",
    "En el ámbito del aprendizaje automático y la inteligencia artificial, las redes neuronales artificiales han emergido como una herramienta fundamental para abordar problemas complejos de reconocimiento de patrones, clasificación y regresión. \n",
    "\n",
    "El algoritmo de retropropagación (backpropagation) es uno de los pilares fundamentales en el campo del aprendizaje profundo y las redes neuronales artificiales. Introducido en la década de 1980, ha permitido entrenar redes neuronales de múltiples capas, superando las limitaciones de los métodos anteriores y abriendo camino a los avances actuales en inteligencia artificial.\n",
    "\n",
    "\n",
    "**Fundamentos de las redes neuronales artificiales**\n",
    "\n",
    "Antes de adentrarnos en el algoritmo de retropropagación, es esencial comprender la estructura y funcionamiento básico de una red neuronal artificial (RNA).\n",
    "\n",
    "1. **Neuronas artificiales**\n",
    "\n",
    "   Una neurona artificial es una unidad de procesamiento que recibe una entrada, realiza una operación matemática y produce una salida. Matemáticamente, se define como:\n",
    "\n",
    "   $$\n",
    "   y = \\phi\\left(\\sum_{i=1}^{n} w_i x_i + b\\right)\n",
    "   $$\n",
    "\n",
    "   Donde:\n",
    "   - $x_i$ son las entradas.\n",
    "   - $w_i$ son los pesos asociados a cada entrada.\n",
    "   - $b$ es el sesgo.\n",
    "   - $\\phi$ es la función de activación.\n",
    "   - $y$ es la salida de la neurona.\n",
    "\n",
    "2. **Capas y arquitectura de la red**\n",
    "\n",
    "   - **Capa de entrada**: Recibe los datos de entrada.\n",
    "   - **Capas ocultas**: Procesan la información mediante neuronas interconectadas.\n",
    "   - **Capa de salida**: Produce la predicción o resultado final.\n",
    "\n",
    "   La red neuronal se construye conectando neuronas en capas, donde la salida de una capa es la entrada de la siguiente.\n",
    "\n",
    "3. **Función de activación**\n",
    "\n",
    "   Las funciones de activación introducen no linealidad en la red, permitiendo que aprenda relaciones complejas entre las entradas y salidas. Algunas funciones comunes incluyen:\n",
    "\n",
    "   - **Sigmoide**:\n",
    "     $$\n",
    "     \\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "     $$\n",
    "   - **ReLU (Unidad lineal rectificada)**:\n",
    "     $$\n",
    "     \\text{ReLU}(z) = \\max(0, z)\n",
    "     $$\n",
    "   - **TanH (Tangente hiperbólica)**:\n",
    "     $$\n",
    "     \\tanh(z) = \\frac{e^{z} - e^{-z}}{e^{z} + e^{-z}}\n",
    "     $$\n",
    "\n",
    "---\n",
    "\n",
    "**El problema del entrenamiento de redes neuronales**\n",
    "\n",
    "El objetivo del entrenamiento es ajustar los pesos y sesgos de la red para que las predicciones $\\hat{y}$ se acerquen lo más posible a los valores objetivos $y$. Esto se logra minimizando una función de pérdida $L(y, \\hat{y})$, que cuantifica el error entre las predicciones y los objetivos.\n",
    "\n",
    "**Función de pérdida común: error cuadrático medio (MSE)**\n",
    "\n",
    "$$\n",
    "L(y, \\hat{y}) = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "Donde $n$ es el número de muestras.\n",
    "\n",
    "**Desafío principal:**\n",
    "\n",
    "- **Optimización de parámetros**: Encontrar los valores óptimos de los pesos y sesgos que minimicen la función de pérdida.\n",
    "- **Computación de gradientes**: Calcular cómo la pérdida cambia con respecto a cada parámetro para ajustar los pesos en la dirección que reduce el error.\n",
    "\n",
    "---\n",
    "\n",
    "**El algoritmo de retropropagación**\n",
    "\n",
    "La retropropagación es un algoritmo que calcula eficientemente los gradientes de la función de pérdida con respecto a todos los pesos y sesgos en la red neuronal. Se basa en la regla de la cadena del cálculo diferencial y permite actualizar los parámetros utilizando métodos de optimización como el descenso de gradiente.\n",
    "\n",
    "**Pasos del algoritmo:**\n",
    "\n",
    "1. **Pase hacia adelante (forward pass)**\n",
    "\n",
    "   - Las entradas se propagan a través de la red para obtener las predicciones $\\hat{y}$.\n",
    "   - Se calcula la función de pérdida $L(y, \\hat{y})$.\n",
    "\n",
    "2. **Pase hacia atrás (backward pass)**\n",
    "\n",
    "   - Se calcula el gradiente de la pérdida con respecto a las salidas de la red.\n",
    "   - Se aplica la regla de la cadena para propagar los gradientes hacia atrás a través de cada capa.\n",
    "   - Se calculan los gradientes con respecto a los pesos y sesgos.\n",
    "\n",
    "3. **Actualización de parámetros**\n",
    "\n",
    "   - Los pesos y sesgos se actualizan utilizando un algoritmo de optimización (p. ej., descenso de gradiente).\n",
    "\n",
    "---\n",
    "\n",
    "**Fundamentos matemáticos de la retropropagación**\n",
    "\n",
    "1. **Regla de la cadena**\n",
    "\n",
    "   La regla de la cadena es una herramienta fundamental en cálculo diferencial que permite calcular la derivada de una función compuesta.\n",
    "\n",
    "   Si $y = f(u)$ y $u = g(x)$, entonces:\n",
    "\n",
    "   $$\n",
    "   \\frac{dy}{dx} = \\frac{dy}{du} \\cdot \\frac{du}{dx}\n",
    "   $$\n",
    "\n",
    "2. **Aplicación en redes neuronales**\n",
    "\n",
    "   En una red neuronal, la salida depende de los pesos y las entradas a través de múltiples funciones compuestas. La retropropagación utiliza la regla de la cadena para calcular las derivadas parciales de la pérdida con respecto a cada parámetro.\n",
    "\n",
    "---\n",
    "\n",
    "**Derivación detallada del algoritmo de retropropagación**\n",
    "\n",
    "Consideremos una red neuronal simple con una capa oculta y una capa de salida, similar al código proporcionado.\n",
    "\n",
    "**Notaciones:**\n",
    "\n",
    "- **Entradas y salidas:**\n",
    "\n",
    "  - $\\mathbf{x} = [x_1, x_2]^T$: Vector de entrada.\n",
    "  - $\\mathbf{y} = [y_1, y_2]^T$: Vector objetivo.\n",
    "  - $\\mathbf{\\hat{y}} = [\\hat{y}_1, \\hat{y}_2]^T$: Predicciones de la red.\n",
    "\n",
    "- **Pesos y sesgos:**\n",
    "\n",
    "  - $\\mathbf{W}^{(1)}$: Matriz de pesos de la capa oculta (dimensión $n_h \\times n_x$).\n",
    "  - $\\mathbf{b}^{(1)}$: Vector de sesgos de la capa oculta (dimensión $n_h$).\n",
    "  - $\\mathbf{W}^{(2)}$: Matriz de pesos de la capa de salida (dimensión $n_y \\times n_h$).\n",
    "  - $\\mathbf{b}^{(2)}$: Vector de sesgos de la capa de salida (dimensión $n_y$).\n",
    "\n",
    "- **Activaciones:**\n",
    "\n",
    "  - $\\mathbf{z}^{(1)} = \\mathbf{W}^{(1)} \\mathbf{x} + \\mathbf{b}^{(1)}$: Entradas a la capa oculta.\n",
    "  - $\\mathbf{a}^{(1)} = \\sigma(\\mathbf{z}^{(1)})$: Salidas de la capa oculta.\n",
    "  - $\\mathbf{z}^{(2)} = \\mathbf{W}^{(2)} \\mathbf{a}^{(1)} + \\mathbf{b}^{(2)}$: Entradas a la capa de salida.\n",
    "  - $\\mathbf{a}^{(2)} = \\sigma(\\mathbf{z}^{(2)})$: Salidas de la red (predicciones $\\mathbf{\\hat{y}}$).\n",
    "\n",
    "**Paso 1: Pase hacia adelante**\n",
    "\n",
    "1. **Cálculo de $\\mathbf{z}^{(1)}$**\n",
    "\n",
    "   $$\n",
    "   \\mathbf{z}^{(1)} = \\mathbf{W}^{(1)} \\mathbf{x} + \\mathbf{b}^{(1)}\n",
    "   $$\n",
    "\n",
    "2. **Cálculo de $\\mathbf{a}^{(1)}$**\n",
    "\n",
    "   $$\n",
    "   \\mathbf{a}^{(1)} = \\sigma(\\mathbf{z}^{(1)})\n",
    "   $$\n",
    "\n",
    "3. **Cálculo de $\\mathbf{z}^{(2)}$**\n",
    "\n",
    "   $$\n",
    "   \\mathbf{z}^{(2)} = \\mathbf{W}^{(2)} \\mathbf{a}^{(1)} + \\mathbf{b}^{(2)}\n",
    "   $$\n",
    "\n",
    "4. **Cálculo de las predicciones $\\mathbf{\\hat{y}}$**\n",
    "\n",
    "   $$\n",
    "   \\mathbf{\\hat{y}} = \\mathbf{a}^{(2)} = \\sigma(\\mathbf{z}^{(2)})\n",
    "   $$\n",
    "\n",
    "5. **Cálculo de la pérdida $L$**\n",
    "\n",
    "   Usando MSE:\n",
    "\n",
    "   $$\n",
    "   L = \\frac{1}{2} \\sum_{i=1}^{n_y} (y_i - \\hat{y}_i)^2\n",
    "   $$\n",
    "\n",
    "**Paso 2: Pase hacia atrás**\n",
    "\n",
    "El objetivo es calcular $\\frac{\\partial L}{\\partial \\mathbf{W}^{(1)}}$, $\\frac{\\partial L}{\\partial \\mathbf{b}^{(1)}}$, $\\frac{\\partial L}{\\partial \\mathbf{W}^{(2)}}$, y $\\frac{\\partial L}{\\partial \\mathbf{b}^{(2)}}$.\n",
    "\n",
    "1. **Gradiente en la capa de salida**\n",
    "\n",
    "   - **Error en la salida ($\\delta^{(2)}$)**:\n",
    "\n",
    "     $$\n",
    "     \\delta^{(2)} = \\frac{\\partial L}{\\partial \\mathbf{z}^{(2)}} = (\\mathbf{\\hat{y}} - \\mathbf{y}) \\circ \\sigma'(\\mathbf{z}^{(2)})\n",
    "     $$\n",
    "\n",
    "     Donde $\\circ$ denota el producto elemento a elemento, y $\\sigma'$ es la derivada de la función sigmoide:\n",
    "\n",
    "     $$\n",
    "     \\sigma'(z) = \\sigma(z)(1 - \\sigma(z))\n",
    "     $$\n",
    "\n",
    "   - **Gradiente de los pesos y sesgos de la capa de salida**:\n",
    "\n",
    "     $$\n",
    "     \\frac{\\partial L}{\\partial \\mathbf{W}^{(2)}} = \\delta^{(2)} (\\mathbf{a}^{(1)})^T\n",
    "     $$\n",
    "\n",
    "     $$\n",
    "     \\frac{\\partial L}{\\partial \\mathbf{b}^{(2)}} = \\delta^{(2)}\n",
    "     $$\n",
    "\n",
    "2. **Gradiente en la capa oculta**\n",
    "\n",
    "   - **Error en la capa oculta ($\\delta^{(1)}$)**:\n",
    "\n",
    "     $$\n",
    "     \\delta^{(1)} = (\\mathbf{W}^{(2)})^T \\delta^{(2)} \\circ \\sigma'(\\mathbf{z}^{(1)})\n",
    "     $$\n",
    "\n",
    "   - **Gradiente de los pesos y sesgos de la capa oculta**:\n",
    "\n",
    "     $$\n",
    "     \\frac{\\partial L}{\\partial \\mathbf{W}^{(1)}} = \\delta^{(1)} \\mathbf{x}^T\n",
    "     $$\n",
    "\n",
    "     $$\n",
    "     \\frac{\\partial L}{\\partial \\mathbf{b}^{(1)}} = \\delta^{(1)}\n",
    "     $$\n",
    "\n",
    "**Paso 3: Actualización de parámetros**\n",
    "\n",
    "Usando el descenso de gradiente, los parámetros se actualizan:\n",
    "\n",
    "- **Pesos**:\n",
    "\n",
    "  $$\n",
    "  \\mathbf{W} = \\mathbf{W} - \\eta \\frac{\\partial L}{\\partial \\mathbf{W}}\n",
    "  $$\n",
    "\n",
    "- **Sesgos**:\n",
    "\n",
    "  $$\n",
    "  \\mathbf{b} = \\mathbf{b} - \\eta \\frac{\\partial L}{\\partial \\mathbf{b}}\n",
    "  $$\n",
    "\n",
    "Donde $\\eta$ es la tasa de aprendizaje.\n",
    "\n",
    "---\n",
    "\n",
    "**Derivación de las ecuaciones de retropropagación**\n",
    "\n",
    "1. **Cálculo de $\\delta^{(2)}$**\n",
    "\n",
    "   La derivada de la pérdida con respecto a $\\mathbf{z}^{(2)}$:\n",
    "\n",
    "   $$\n",
    "   \\frac{\\partial L}{\\partial z^{(2)}_i} = \\frac{\\partial L}{\\partial \\hat{y}_i} \\cdot \\frac{\\partial \\hat{y}_i}{\\partial z^{(2)}_i}\n",
    "   $$\n",
    "\n",
    "   Dado que:\n",
    "\n",
    "   $$\n",
    "   \\frac{\\partial L}{\\partial \\hat{y}_i} = \\hat{y}_i - y_i\n",
    "   $$\n",
    "\n",
    "   Y:\n",
    "\n",
    "   $$\n",
    "   \\frac{\\partial \\hat{y}_i}{\\partial z^{(2)}_i} = \\sigma'(z^{(2)}_i)\n",
    "   $$\n",
    "\n",
    "   Entonces:\n",
    "\n",
    "   $$\n",
    "   \\delta^{(2)}_i = (\\hat{y}_i - y_i) \\sigma'(z^{(2)}_i)\n",
    "   $$\n",
    "\n",
    "2. **Cálculo de $\\delta^{(1)}$**\n",
    "\n",
    "   Para cada neurona $j$ en la capa oculta:\n",
    "\n",
    "   $$\n",
    "   \\frac{\\partial L}{\\partial z^{(1)}_j} = \\sum_{i} \\frac{\\partial L}{\\partial z^{(2)}_i} \\cdot \\frac{\\partial z^{(2)}_i}{\\partial a^{(1)}_j} \\cdot \\frac{\\partial a^{(1)}_j}{\\partial z^{(1)}_j}\n",
    "   $$\n",
    "\n",
    "   Dado que:\n",
    "\n",
    "   $$\n",
    "   \\frac{\\partial z^{(2)}_i}{\\partial a^{(1)}_j} = W^{(2)}_{ij}\n",
    "   $$\n",
    "\n",
    "   Y:\n",
    "\n",
    "   $$\n",
    "   \\frac{\\partial a^{(1)}_j}{\\partial z^{(1)}_j} = \\sigma'(z^{(1)}_j)\n",
    "   $$\n",
    "\n",
    "   Entonces:\n",
    "\n",
    "   $$\n",
    "   \\delta^{(1)}_j = \\left( \\sum_{i} \\delta^{(2)}_i W^{(2)}_{ij} \\right) \\sigma'(z^{(1)}_j)\n",
    "   $$\n",
    "\n",
    "---\n",
    "\n",
    "**Interpretación intuitiva del algoritmo**\n",
    "\n",
    "- **Propagación de errores**: Los errores se propagan desde la capa de salida hacia las capas anteriores, ajustando los pesos en cada capa para reducir el error en la salida.\n",
    "- **Uso de la regla de la cadena**: Permite descomponer el gradiente global en gradientes locales, facilitando el cálculo de derivadas en redes profundas.\n",
    "- **Actualización incremental**: Los pesos se actualizan en pequeños incrementos, moviéndose en la dirección que reduce la pérdida.\n",
    "\n",
    "---\n",
    "\n",
    "**Consideraciones sobre la función de activación sigmoide**\n",
    "\n",
    "Aunque la función sigmoide es popular por su interpretación probabilística y su salida en el rango (0, 1), presenta algunos desafíos:\n",
    "\n",
    "- **Desvanecimiento del gradiente**: Para valores extremos de $z$, la derivada $\\sigma'(z)$ se acerca a cero, lo que puede ralentizar el aprendizaje.\n",
    "- **Salida no cero-centrada**: La salida de la sigmoide siempre es positiva, lo que puede afectar la dinámica del entrenamiento.\n",
    "\n",
    "Alternativas como ReLU o funciones de activación cero-centradas pueden mitigar estos problemas.\n",
    "\n",
    "---\n",
    "\n",
    "**Implementación del algoritmo en PyTorch**\n",
    "\n",
    "PyTorch facilita la implementación del algoritmo de retropropagación mediante su módulo `autograd`, que automatiza el cálculo de gradientes.\n",
    "\n",
    "1. **Definición del modelo**\n",
    "\n",
    "   Utilizando `nn.Module`, se definen las capas y las funciones de activación.\n",
    "\n",
    "   ```python\n",
    "   class NeuralNetwork(nn.Module):\n",
    "       def __init__(self, num_inputs, num_hidden, num_outputs):\n",
    "           super(NeuralNetwork, self).__init__()\n",
    "           self.hidden_layer = nn.Linear(num_inputs, num_hidden)\n",
    "           self.output_layer = nn.Linear(num_hidden, num_outputs)\n",
    "           self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "       def forward(self, x):\n",
    "           hidden = self.sigmoid(self.hidden_layer(x))\n",
    "           output = self.sigmoid(self.output_layer(hidden))\n",
    "           return output\n",
    "   ```\n",
    "\n",
    "2. **Proceso de entrenamiento**\n",
    "\n",
    "   - **Pase hacia adelante**: `outputs = model(inputs)`\n",
    "   - **Cálculo de la pérdida**: `loss = criterion(outputs, targets)`\n",
    "   - **Retropropagación**: `loss.backward()`\n",
    "   - **Actualización de parámetros**: `optimizer.step()`\n",
    "\n",
    "3. **Automatización de gradientes**\n",
    "\n",
    "   PyTorch rastrea automáticamente las operaciones sobre los tensores y calcula los gradientes necesarios durante `loss.backward()`.\n",
    "\n",
    "---\n",
    "\n",
    "**Limitaciones y consideraciones prácticas**\n",
    "\n",
    "1. **Tasa de aprendizaje**\n",
    "\n",
    "   - **Selección apropiada**: Una tasa de aprendizaje demasiado alta puede provocar oscilaciones o divergencia; demasiado baja puede ralentizar el aprendizaje.\n",
    "   - **Algoritmos adaptativos**: Optimizadores como Adam o RMSprop ajustan la tasa de aprendizaje durante el entrenamiento.\n",
    "\n",
    "2. **Sobreajuste**\n",
    "\n",
    "   - **Definición**: El modelo aprende demasiado bien los datos de entrenamiento y no generaliza a datos nuevos.\n",
    "   - **Mitigación**: Uso de regularización, early stopping, o aumento de datos.\n",
    "\n",
    "3. **Inicialización de pesos**\n",
    "\n",
    "   - **Importancia**: Una mala inicialización puede dificultar el entrenamiento.\n",
    "   - **Estrategias**: Inicialización aleatoria con distribuciones específicas o técnicas como Xavier/He inicialización.\n",
    "\n",
    "4. **Funciones de activación alternativas**\n",
    "\n",
    "   - **ReLU**: Evita el problema del desvanecimiento del gradiente en redes profundas.\n",
    "   - **Leaky ReLU**: Variante que permite un pequeño gradiente cuando la entrada es negativa.\n",
    "\n",
    "---\n",
    "\n",
    "**Avances posteriores al algoritmo de retropropagación**\n",
    "\n",
    "Aunque la retropropagación sigue siendo el método estándar para entrenar redes neuronales, se han desarrollado técnicas y mejoras:\n",
    "\n",
    "1. **Batch normalization**\n",
    "\n",
    "   - **Objetivo**: Acelerar el entrenamiento y mejorar la estabilidad.\n",
    "   - **Método**: Normalizar las activaciones de cada mini-lote.\n",
    "\n",
    "2. **Dropout**\n",
    "\n",
    "   - **Objetivo**: Evitar el sobreajuste.\n",
    "   - **Método**: Durante el entrenamiento, se \"apagan\" aleatoriamente neuronas.\n",
    "\n",
    "3. **Optimizadores avanzados**\n",
    "\n",
    "   - **Adam**: Combina las ventajas de AdaGrad y RMSprop.\n",
    "   - **Adadelta, AdaMax**: Adaptan la tasa de aprendizaje basándose en el historial de gradientes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca 0, Perdida: 0.26962941884994507\n",
      "Epoca 1000, Perdida: 0.00028327354812063277\n",
      "Epoca 2000, Perdida: 9.581194899510592e-05\n",
      "Epoca 3000, Perdida: 4.695755342254415e-05\n",
      "Epoca 4000, Perdida: 2.686593506950885e-05\n",
      "Epoca 5000, Perdida: 1.674771192483604e-05\n",
      "Epoca 6000, Perdida: 1.1025298590539023e-05\n",
      "Epoca 7000, Perdida: 7.537267265433911e-06\n",
      "Epoca 8000, Perdida: 5.296076324157184e-06\n",
      "Epoca 9000, Perdida: 3.7999598134774715e-06\n",
      "Pérdida de validación: 0.0014848790597170591\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, num_inputs, num_hidden, num_outputs):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.hidden_layer = nn.Linear(num_inputs, num_hidden)\n",
    "        self.output_layer = nn.Linear(num_hidden, num_outputs)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden = self.sigmoid(self.hidden_layer(x))\n",
    "        output = self.sigmoid(self.output_layer(hidden))\n",
    "        return output\n",
    "\n",
    "# Cambiando el nombre de la instancia para evitar confusión\n",
    "model = NeuralNetwork(num_inputs=2, num_hidden=2, num_outputs=2)\n",
    "\n",
    "# Optimizador y función de pérdida\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.5)\n",
    "criterion = nn.MSELoss()  # Instancia correctamente MSELoss\n",
    "\n",
    "# Datos de entrenamiento\n",
    "inputs = torch.tensor([[0.05, 0.1]], dtype=torch.float32)\n",
    "targets = torch.tensor([[0.01, 0.99]], dtype=torch.float32)\n",
    "\n",
    "# Bucle de entrenamiento\n",
    "for i in range(10000):\n",
    "    model.zero_grad()           # Resetea los gradientes\n",
    "    outputs = model(inputs)     # Pase hacia adelante\n",
    "    loss = criterion(outputs, targets)  # Calcula la pérdida\n",
    "    loss.backward()             # Pase hacia atrás\n",
    "    optimizer.step()            # Actualiza los parámetros\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        print(f'Epoca {i}, Perdida: {loss.item()}')\n",
    "\n",
    "# Código opcionalmente añadido para validación/pruebas\n",
    "# Supongamos que tenemos datos de validación:\n",
    "validation_inputs = torch.tensor([[0.1, 0.2]], dtype=torch.float32)\n",
    "validation_targets = torch.tensor([[0.05, 0.95]], dtype=torch.float32)\n",
    "\n",
    "# Evaluar el modelo en modo de evaluación\n",
    "model.eval()\n",
    "with torch.no_grad():  # Desactiva el cálculo de gradientes\n",
    "    validation_outputs = model(validation_inputs)\n",
    "    validation_loss = criterion(validation_outputs, validation_targets)\n",
    "    print(f'Pérdida de validación: {validation_loss.item()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicios\n",
    "\n",
    "**Ejercicio 1:** Implementación manual del algoritmo  de retropropagación\n",
    "\n",
    "Crea una red neuronal simple (por ejemplo, una red con una capa oculta) desde cero en Python. Implementa manualmente el algoritmo de retropropagación para actualizar los pesos de la red.  Utiliza esta red para entrenar un modelo que pueda clasificar puntos en dos clases basadas en su posición en un plano 2D. Genera datos sintéticos que sean linealmente separables.\n",
    "\n",
    "**Ejercicio 2:**  Comparación de funciones de activación\n",
    "\n",
    "Modifica la red del ejercicio 1 para probar diferentes funciones de activación (ReLU, sigmoidal, tanh) en la capa oculta.  Compara el rendimiento del entrenamiento con cada función de activación. Observa cómo cambia la rapidez de convergencia y si alguna configuración es particularmente propensa a problemas como el desvanecimiento o la explosión de gradientes.\n",
    "\n",
    "**Ejercicio 3:** Retropropagación con regularización\n",
    "\n",
    "Añade L2 (ridge) o L1 (lasso) regularización a la red neuronal que creaste en el ejercicio 1. Entrena la red en un conjunto de datos más complejo que introduzca algo de ruido y observa si la regularización ayuda a mejorar la generalización del modelo.\n",
    "\n",
    "**Ejercicio 4:** Experimentando con tamaños de batch\n",
    "\n",
    "Implementa la retropropagación utilizando diferentes tamaños de batch: desde el descenso de gradiente estocástico (un ejemplo a la vez) hasta el descenso de gradiente por lotes (usando todo el conjunto de datos a la vez). Analiza cómo cambian la estabilidad y la velocidad de convergencia del entrenamiento con los diferentes tamaños de batch. Considera incluir una visualización de la disminución de la pérdida a lo largo de las iteraciones para cada configuración de tamaño de batch.\n",
    "\n",
    "**Ejercicio 5:**  Optimización de Hiperparámetros\n",
    "\n",
    "Utiliza la red neuronal del ejercicio 1 y experimenta con diferentes tasas de aprendizaje y números de épocas de entrenamiento. Implementa una búsqueda de cuadrícula o aleatoria para encontrar la combinación óptima de tasa de aprendizaje y número de épocas. Evalúa el rendimiento del modelo en un conjunto de validación para determinar la mejor configuración de hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tus respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation Through Time (BPTT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este documento, explicaremos el algoritmo de retropropagación a través del tiempo (BPTT), un método de retropropagación utilizado para entrenar redes neuronales recurrentes (RNN). Mostraremos tanto la derivación matemática como la implementación en código utilizando PyTorch, lo que nos permitirá comparar los gradientes calculados automáticamente por PyTorch con los calculados manualmente.\n",
    "\n",
    "#### Definición matemática de una RNN\n",
    "\n",
    "En primer lugar, definamos matemáticamente cómo funciona una RNN en cada paso de tiempo $ t $.\n",
    "\n",
    "Sea $ x_t \\in \\mathbb{R}^{d_x} $ un vector de entrada en el paso de tiempo $ t $. Una RNN de tamaño $ d_h $ calcula su estado oculto $ h_t $ como:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "  r_t &= U x_t + V h_{t-1} + b \\\\\n",
    "  h_t &= f(r_t)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "donde:\n",
    "- $ U \\in \\mathbb{R}^{d_h \\times d_x} $ y $ V \\in \\mathbb{R}^{d_h \\times d_h} $ son matrices de pesos,\n",
    "- $ b \\in \\mathbb{R}^{d_h} $ es un vector de sesgo,\n",
    "- $ f $ es una función de activación no lineal, comúnmente la tangente hiperbólica ($ \\tanh $).\n",
    "\n",
    "El vector de salida $ y_t \\in \\mathbb{R}^{d_o} $ se calcula como:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "  s_t &= W h_t + c \\\\\n",
    "  y_t &= g(s_t)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "donde:\n",
    "- $ W \\in \\mathbb{R}^{d_o \\times d_h} $ es una matriz de pesos,\n",
    "- $ c \\in \\mathbb{R}^{d_o} $ es un vector de sesgo,\n",
    "- $ g $ es una función de salida no lineal, como la softmax para tareas de clasificación.\n",
    "\n",
    "**Nota:** Los parámetros $U$, $V$, $W$, $b $ y $ c $ se comparten a lo largo de todos los pasos de tiempo, es decir, no hay matrices de pesos separadas para cada paso de tiempo.\n",
    "\n",
    "#### Funciones de activación\n",
    "\n",
    "- **Función de activación oculta ($f$):** Comúnmente se utiliza la tangente hiperbólica ($\\tanh$) o la función sigmoide ($\\sigma$) debido a su capacidad para introducir no linealidades en el modelo.\n",
    "  \n",
    "  $$\n",
    "  f(r_t) = \\tanh(r_t) \\quad \\text{o} \\quad f(r_t) = \\sigma(r_t)\n",
    "  $$\n",
    "\n",
    "- **Función de salida ($g$):** Depende de la tarea específica. Por ejemplo, para problemas de clasificación, se emplea la función softmax:\n",
    "\n",
    "  $$\n",
    "  g(s_t)_i = \\frac{e^{s_{t,i}}}{\\sum_{j=1}^{d_o} e^{s_{t,j}}}\n",
    "  $$\n",
    "\n",
    "\n",
    "Durante el entrenamiento de una RNN, se define una función de pérdida que acumula las diferencias entre las predicciones $y_t$ y las etiquetas reales a lo largo de todos los pasos de tiempo. \n",
    "Debido a la naturaleza recurrente de las RNN, los errores deben propagarse hacia atrás a través de todos los pasos de tiempo para actualizar los parámetros $ U $, $V$, $W$, $b$ y $c$. Este proceso se denomina Retropropagación a través del Tiempo (BPTT).\n",
    "\n",
    "El algoritmo BPTT extiende la retropropagación estándar al descomponer la RNN a través del tiempo y aplicar la retropropagación en esta estructura expandida. Esto permite calcular los gradientes de la función de pérdida respecto a cada uno de los parámetros de la red, teniendo en cuenta las dependencias temporales.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proceso del algoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sea $L = \\mathcal{L}(y_t)$ la pérdida de nuestra RNN. Uno podría intentar derivar los gradientes de $U$, $V$, $W$ de manera ingenua. Por ejemplo, para calcular el gradiente sobre $W$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W_{ij}} = \\sum_k \\frac{\\partial L}{\\partial (s_t)_k} \\frac{\\partial (s_t)_k}{\\partial W_{ij}}\n",
    "$$\n",
    "\n",
    "Dado que\n",
    "\n",
    "$$\n",
    "\\frac{\\partial (s_t)_k}{\\partial W_{ij}} =\n",
    "\\begin{cases}\n",
    "0 & k \\neq i \\\\\n",
    "(h_t)_j & \\text{de lo contrario}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "tenemos\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W_{ij}} = \\frac{\\partial L}{\\partial (s_t)_i}.(h_t)_j\n",
    "$$\n",
    "\n",
    "O, en notación matricial\n",
    "\n",
    "$$\n",
    "\\overline{W} = \\overline{s}_t.h_t^{\\top}\n",
    "$$\n",
    "\n",
    "donde la notación de barra denota el gradiente de $L$ con respecto a la matriz correspondiente, es decir, $\\overline{A}_{ij} = \\frac{\\partial L}{\\partial A_{ij}}$ y $\\overline{a}_i = \\frac{\\partial L}{\\partial a_i}$.\n",
    "\n",
    "Sin embargo, esto es **incorrecto**. Dado que $W$ se comparte a lo largo de los pasos de tiempo, contribuye a $s_t$ para *todos* los pasos de tiempo  $t$. Por lo tanto, al calcular el gradiente, necesitamos sumar los gradientes de todos los pasos de tiempo. En otras palabras, lo que necesitamos es:\n",
    "\n",
    "$$\n",
    "\\overline{W} = \\sum_t \\overline{s}_t. h_t^{\\top}\n",
    "$$\n",
    "\n",
    "Los gradientes sobre $U$ y $V$ se pueden calcular de manera similar, es decir\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "  \\overline{U} &= \\sum_t \\overline{r}_t . x_t^{\\top} \\\\\n",
    "  \\overline{V} &= \\sum_t \\overline{r}_t .h_{t-1}^{\\top}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "**Gradiente sobre $r_t$**\n",
    "\n",
    "Gradiente sobre $r_t$ es:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "  \\frac{\\partial L}{\\partial (r_t)_i}\n",
    "  &= \\sum_j \\frac{\\partial L}{\\partial (h_t)_j}. \\frac{\\partial (h_t)_j}{\\partial (r_t)_i} \\\\\n",
    "  &= \\frac{\\partial L}{\\partial (h_t)_i}. f' (r_t)_i\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "O, en notación vectorial\n",
    "\n",
    "$$\n",
    "\\overline{r}_t = \\overline{h}_t \\circ f' (r_t)\n",
    "$$\n",
    "\n",
    "De manera similar, el gradiente sobre $s_t$ se puede mostrar como $\\overline{s}_t = \\overline{y}_t \\circ g' (s_t)$.\n",
    "\n",
    "**Gradiente sobre $h_t$** \n",
    "\n",
    "Por último, necesitamos calcular $\\overline{h}_t$. Note que $h_t$ contribuye a $s_t$, y si $t$ no es el último paso de tiempo, entonces también contribuye a $r_{t+1}$. Por lo tanto, si $T$ denota el último paso de tiempo, entonces\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "  \\frac{\\partial L}{\\partial (h_T)_i}\n",
    "  &= \\sum_j \\frac{\\partial L}{\\partial (s_T)_j}. \\frac{\\partial (s_T)_j}{\\partial (h_T)_i} \\\\\n",
    "  &= \\sum_j \\frac{\\partial L}{\\partial (s_T)_j}.W_{ji}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "y para $t < T$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "  \\frac{\\partial L}{\\partial (h_t)_i}\n",
    "  &= \\sum_j \\frac{\\partial L}{\\partial (s_t)_j}. \\frac{\\partial (s_t)_j}{\\partial (h_t)_i}\n",
    "  + \\sum_k \\frac{\\partial L}{\\partial (r_{t+1})_k}. \\frac{\\partial (r_{t+1})_k}{\\partial (h_t)_i} \\\\\n",
    "  &= \\sum_j \\frac{\\partial L}{\\partial (s_t)_j}.W_{ji}\n",
    "  + \\sum_k \\frac{\\partial L}{\\partial (r_{t+1})_k}.V_{ki}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "En notación matricial (y combinando los dos)\n",
    "\n",
    "$$\n",
    "\\overline{h}_t = W^{\\top}. \\overline{s}_t +\n",
    "\\begin{cases}\n",
    "0 & t = T \\\\\n",
    "V^{\\top}. \\overline{r}_{t+1} & \\text{si} t < T\n",
    "\\end{cases}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementacion en PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La implementación del cálculo hacia adelante es bastante directa. Comenzamos desde el paso de tiempo 1 y calculamos $ r_t $, $ h_t $, $ s_t $ y $ y_t $, dadas las entradas $ x_t $ y $ h_{t-1} $, hasta el último paso de tiempo $ T $. Iniciamos desde el paso de tiempo 1 porque, en la relación de recurrencia, para calcular $ r_t $ necesitamos $ h_{t-1} $. Por lo tanto, el paso de tiempo anterior debe completarse primero.\n",
    "\n",
    "La implementación del cálculo hacia atrás es similar, pero en este caso comenzamos desde el último paso de tiempo $ T $ y retrocedemos hasta el primero. Esto se debe a que, en la relación de recurrencia, necesitamos $ \\overline{r}_{t+1} $ para calcular $ \\overline{h}_t $. Así, el siguiente paso de tiempo debe completarse previamente. Además, a medida que iteramos, necesitamos acumular los gradientes en $ U $, $ V $ y $ W $.\n",
    "\n",
    "Primero, vamos a crear una clase `RNNCell`. Esta clase es responsable de un solo paso de tiempo y contiene métodos `forward` y `backward` que realizan los cálculos hacia adelante y hacia atrás, respectivamente.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNCell:\n",
    "    \"\"\"Una celda RNN responsable de un solo paso de tiempo.\n",
    "\n",
    "    Args:\n",
    "        inp_sz (int): Tamaño de la entrada.\n",
    "        hid_sz (int): Tamaño del estado oculto.\n",
    "        out_sz (int): Tamaño de la salida.\n",
    "    \"\"\"\n",
    "    def __init__(self, inp_sz, hid_sz, out_sz):\n",
    "        self.inp_sz = inp_sz\n",
    "        self.hid_sz = hid_sz\n",
    "        self.out_sz = out_sz\n",
    "\n",
    "        # U, V, W son los parámetros, por lo que establecemos requires_grad=True\n",
    "        # para indicar a PyTorch que necesitamos calcular los gradientes\n",
    "        self.U = torch.empty(hid_sz, inp_sz, requires_grad=True)\n",
    "        self.V = torch.empty(hid_sz, hid_sz, requires_grad=True)\n",
    "        self.W = torch.empty(out_sz, hid_sz, requires_grad=True)\n",
    "\n",
    "        # Estos son los gradientes en U, V y W que calcularemos\n",
    "        # manualmente. También los compararemos con\n",
    "        # los gradientes calculados por PyTorch para ver si nuestro\n",
    "        # cálculo de gradientes es correcto.\n",
    "        self.U_grad = torch.zeros_like(self.U)\n",
    "        self.V_grad = torch.zeros_like(self.V)\n",
    "        self.W_grad = torch.zeros_like(self.W)\n",
    "        \n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"Inicializar parámetros.\n",
    "\n",
    "        Los parámetros se inicializarán desde la distribución uniforme U(-0.1, 0.1).\n",
    "        \"\"\"\n",
    "        s = 0.1  # un valor mayor puede hacer que los gradientes exploten\n",
    "        torch.nn.init.uniform_(self.U, -s, s)\n",
    "        torch.nn.init.uniform_(self.V, -s, s)\n",
    "        torch.nn.init.uniform_(self.W, -s, s)\n",
    "    def zero_grad(self):\n",
    "        \"\"\"Se pone el gradiente a cero\"\"\"\n",
    "        self.U_grad.zero_()\n",
    "        self.V_grad.zero_()\n",
    "        self.W_grad.zero_()\n",
    "    \n",
    "    def forward(self, x, hp):\n",
    "        \"\"\"Realizar el cálculo hacia adelante.\n",
    "        \n",
    "        Args:\n",
    "            x (Tensor): Entrada en el paso de tiempo actual.\n",
    "            hp (Tensor): Estado oculto en el paso de tiempo anterior.\n",
    "            \n",
    "        Returns:\n",
    "            Tensor: Salida en el paso de tiempo actual.\n",
    "            Tensor: Estado oculto en el paso de tiempo actual.\n",
    "        \"\"\"\n",
    "        _, h, _, y = self._get_internals(x, hp)\n",
    "        return y, h\n",
    "\n",
    "    def backward(self, y_grad, rn_grad, x, hp):\n",
    "        \"\"\"Realizar el cálculo hacia atrás.\n",
    "        \n",
    "        Args:\n",
    "            y_grad (Tensor): Gradiente sobre la salida en el paso de tiempo actual.\n",
    "            rn_grad (Tensor): Gradiente sobre el vector r en el siguiente paso de tiempo.\n",
    "            x (Tensor): Entrada en el paso de tiempo actual que se pasó a `forward`.\n",
    "            hp (Tensor): Estado oculto en el paso de tiempo anterior que se pasó a `forward`.\n",
    "            \n",
    "        Returns:\n",
    "            Tensor: Gradiente sobre el vector r en el paso de tiempo actual.\n",
    "        \"\"\"\n",
    "        # Obtener los vectores internos r, h, y s del cálculo hacia adelante\n",
    "        r, h, s, _ = self._get_internals(x, hp)\n",
    "\n",
    "        s_grad = y_grad * torch.sigmoid(s) * (1-torch.sigmoid(s))\n",
    "        h_grad = self.W.t().matmul(s_grad) + self.V.t().matmul(rn_grad)\n",
    "        r_grad = h_grad * torch.sigmoid(r) * (1-torch.sigmoid(r))\n",
    "\n",
    "        # Los gradientes de los parámetros se acumulan\n",
    "        self.U_grad += r_grad.view(-1, 1).matmul(x.view(1, -1))\n",
    "        self.V_grad += r_grad.view(-1, 1).matmul(hp.view(1, -1))\n",
    "        self.W_grad += s_grad.view(-1, 1).matmul(h.view(1, -1))\n",
    "\n",
    "        return r_grad\n",
    "\n",
    "    def _get_internals(self, x, hp):\n",
    "        # Estos son los calculos forward reales\n",
    "        r = self.U.matmul(x) + self.V.matmul(hp)\n",
    "        h = torch.sigmoid(r)\n",
    "        s = self.W.matmul(h)\n",
    "        y = torch.sigmoid(s)\n",
    "        \n",
    "        return r, h, s, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, creemos una clase RNN. Esta clase acepta una RNNCell y es responsable de realizar la iteración sobre los pasos de tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    def __init__(self, cell):\n",
    "        self.cell = cell\n",
    "    \n",
    "    def forward(self, xs, h0):\n",
    "        \"\"\"Realiza la computación hacia adelante para todos los pasos de tiempo.\n",
    "        \n",
    "        Args:\n",
    "            xs (Tensor): Tensor 2-D de entradas para cada paso de tiempo. La\n",
    "                primera dimensión corresponde al número de pasos de tiempo.\n",
    "            h0 (Tensor): Estado oculto inicial.\n",
    "            \n",
    "        Returns:\n",
    "            Tensor: Tensor 2-D de salidas para cada paso de tiempo. La primera\n",
    "                dimensión corresponde al número de pasos de tiempo.\n",
    "            Tensor: Tensor 2-D de estados ocultos para cada paso de tiempo más\n",
    "                `h0`. La primera dimensión corresponde al número de pasos de\n",
    "                tiempo.\n",
    "        \"\"\"\n",
    "        ys, hs = [], [h0]  # Inicializa listas vacías para almacenar las salidas y los estados ocultos\n",
    "        for x in xs:\n",
    "            y, h = self.cell.forward(x, hs[-1])  # Calcula la salida y el siguiente estado oculto\n",
    "            ys.append(y)  # Agrega la salida a la lista de salidas\n",
    "            hs.append(h)  # Agrega el estado oculto al final de la lista de estados ocultos\n",
    "        return torch.stack(ys), torch.stack(hs)  # Apila las salidas y los estados ocultos en tensores\n",
    "    \n",
    "    def backward(self, ys_grad, xs, hs):\n",
    "        \"\"\"Realiza la computación hacia atrás para todos los pasos de tiempo.\n",
    "        \n",
    "        Args:\n",
    "            ys_grad (Tensor): Tensor 2-D de los gradientes en las salidas\n",
    "                para cada paso de tiempo. La primera dimensión corresponde a\n",
    "                el número de pasos de tiempo.\n",
    "            xs (Tensor): Tensor 2-D de entradas para cada paso de tiempo que\n",
    "                fue pasado a `forward`.\n",
    "            hs (Tensor): Tensor 2-D de estados ocultos que es devuelto por\n",
    "                `forward`.\n",
    "        \"\"\"\n",
    "        # Para el último paso de tiempo, el gradiente en r es cero\n",
    "        rn_grad = torch.zeros(self.cell.hid_sz)  # Inicializa el gradiente de la celda recurrente como cero\n",
    "\n",
    "        for y_grad, x, hp in reversed(list(zip(ys_grad, xs, hs))):\n",
    "            rn_grad = cell.backward(y_grad, rn_grad, x, hp)  # Calcula el gradiente para cada paso de tiempo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, la función de pérdida. Aquí utilizamos una pérdida simple de suma de cuadrados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(ys, ts):\n",
    "    return 0.5 * torch.sum((ys - ts)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, construimos nuestra RNN. Tendrá un tamaño de entrada de 2, un tamaño oculto de 3 y un tamaño de salida de 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = RNNCell(2, 4, 5)\n",
    "rnn = RNN(cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, creamos entradas y objetivos ficticios para nuestra RNN. Estableceremos el número de pasos de tiempo en 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = torch.rand(3, cell.inp_sz)\n",
    "hp = torch.rand(cell.hid_sz)\n",
    "ts = torch.rand(3, cell.out_sz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, realizamos la computación del forward y calculamos la pérdida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys, hs = rnn.forward(xs, hp)\n",
    "loss = compute_loss(ys, ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6165, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Veamos los gradientes calculados por PyTorch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4026e-04, -3.9695e-04],\n",
       "        [ 8.1963e-05,  4.9689e-04],\n",
       "        [ 2.1676e-03,  1.2979e-03],\n",
       "        [-5.3256e-04, -2.2029e-04]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.cell.U.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0002, -0.0005, -0.0005, -0.0003],\n",
       "        [ 0.0010,  0.0004,  0.0004,  0.0007],\n",
       "        [ 0.0033,  0.0022,  0.0023,  0.0027],\n",
       "        [-0.0010, -0.0004, -0.0004, -0.0007]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.cell.V.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0101,  0.0116,  0.0111,  0.0125],\n",
       "        [-0.0587, -0.0549, -0.0562, -0.0527],\n",
       "        [ 0.0243,  0.0226,  0.0239,  0.0212],\n",
       "        [-0.0436, -0.0416, -0.0428, -0.0403],\n",
       "        [ 0.0722,  0.0696,  0.0714,  0.0678]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.cell.W.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, ejecutemos nuestra computación backward y comparemos el resultado con el de PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esto se obtiene de nuestra función de pérdida de suma de cuadrados\n",
    "ys_grad = ys - ts\n",
    "\n",
    "with torch.no_grad():  # necesario para que PyTorch no genere un erro\n",
    "    rnn.cell.zero_grad()\n",
    "    rnn.backward(ys_grad, xs, hs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora veamos si nuestros gradientes calculados manualmente son correctos, es decir, si son iguales a los de PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4026e-04, -3.9695e-04],\n",
       "        [ 8.1963e-05,  4.9689e-04],\n",
       "        [ 2.1676e-03,  1.2979e-03],\n",
       "        [-5.3256e-04, -2.2029e-04]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.cell.U_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0002, -0.0005, -0.0005, -0.0003],\n",
       "        [ 0.0010,  0.0004,  0.0004,  0.0007],\n",
       "        [ 0.0033,  0.0022,  0.0023,  0.0027],\n",
       "        [-0.0010, -0.0004, -0.0004, -0.0007]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.cell.V_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0101,  0.0116,  0.0111,  0.0125],\n",
       "        [-0.0587, -0.0549, -0.0562, -0.0527],\n",
       "        [ 0.0243,  0.0226,  0.0239,  0.0212],\n",
       "        [-0.0436, -0.0416, -0.0428, -0.0403],\n",
       "        [ 0.0722,  0.0696,  0.0714,  0.0678]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.cell.W_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "¡Y son iguales! Así que nuestra computación es realmente correcta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicios\n",
    "\n",
    "**Ejercicio 1**: Derivación manual de BPTT\n",
    "\n",
    "Dado un simple RNN con una capa oculta y una función de activación sigmoide, realiza la derivación manual de los gradientes para los parámetros $U$, $V$ y $W$ utilizando BPTT. Asume que la RNN tiene una sola unidad oculta y procesa secuencias de tres tiempos.\n",
    "\n",
    "**Ejercicio 2**: Implementación de BPTT desde cero\n",
    "\n",
    "Implementa una RNN simple en Python sin usar bibliotecas de deep learning como TensorFlow o PyTorch. Tu RNN debe incluir métodos de forward y backward, y debe ser capaz de procesar secuencias de longitud variable.\n",
    "\n",
    "**Ejercicio 3**: Comparación de gradientes\n",
    "\n",
    "Utiliza PyTorch para crear una RNN simple y compara los gradientes que calcula automáticamente con los que calculaste manualmente en el ejercicio 1 o implementaste en el ejercicio 2.\n",
    "\n",
    "**Ejercicio 4:** Exploración de la explosión y desvanecimiento de gradientes\n",
    "\n",
    "Modifica la RNN implementada en el ejercicio 2 para incluir secuencias de entrada de diferentes longitudes. Experimenta con inicializaciones de parámetros y observa cómo afectan a la magnitud de los gradientes durante el entrenamiento.\n",
    "\n",
    "**Ejercicio 5:** BPTT con diferentes funciones de activación\n",
    "\n",
    "Implementa varias funciones de activación (ReLU, tanh, sigmoide) en tu RNN del ejercicio 2. Entrena tu modelo en un conjunto de datos de prueba simple (puede ser generado sintéticamente) y compara cómo la elección de la función de activación afecta el rendimiento.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tus respuestas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
