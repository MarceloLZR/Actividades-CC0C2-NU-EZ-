{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagación\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, num_inputs, num_hidden, num_outputs):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.hidden_layer = nn.Linear(num_inputs, num_hidden)\n",
    "        self.output_layer = nn.Linear(num_hidden, num_outputs)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden = self.sigmoid(self.hidden_layer(x))\n",
    "        output = self.sigmoid(self.output_layer(hidden))\n",
    "        return output\n",
    "\n",
    "# Cambiando el nombre de la instancia para evitar confusión\n",
    "model = NeuralNetwork(num_inputs=2, num_hidden=2, num_outputs=2)\n",
    "\n",
    "# Optimizador y función de pérdida\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.5)\n",
    "criterion = nn.MSELoss()  # Instancia correctamente MSELoss\n",
    "\n",
    "# Datos de entrenamiento\n",
    "inputs = torch.tensor([[0.05, 0.1]], dtype=torch.float32)\n",
    "targets = torch.tensor([[0.01, 0.99]], dtype=torch.float32)\n",
    "\n",
    "# Bucle de entrenamiento\n",
    "for i in range(10000):\n",
    "    model.zero_grad()           # Resetea los gradientes\n",
    "    outputs = model(inputs)     # Pase hacia adelante\n",
    "    loss = criterion(outputs, targets)  # Calcula la pérdida\n",
    "    loss.backward()             # Pase hacia atrás\n",
    "    optimizer.step()            # Actualiza los parámetros\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        print(f'Epoch {i}, Loss: {loss.item()}')\n",
    "\n",
    "# Código opcionalmente añadido para validación/pruebas\n",
    "# Supongamos que tenemos datos de validación:\n",
    "validation_inputs = torch.tensor([[0.1, 0.2]], dtype=torch.float32)\n",
    "validation_targets = torch.tensor([[0.05, 0.95]], dtype=torch.float32)\n",
    "\n",
    "# Evaluar el modelo en modo de evaluación\n",
    "model.eval()\n",
    "with torch.no_grad():  # Desactiva el cálculo de gradientes\n",
    "    validation_outputs = model(validation_inputs)\n",
    "    validation_loss = criterion(validation_outputs, validation_targets)\n",
    "    print(f'Pérdida de validación: {validation_loss.item()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicios\n",
    "\n",
    "**Ejercicio 1:** Implementación manual del algoritmo  de retropropagación\n",
    "\n",
    "Crea una red neuronal simple (por ejemplo, una red con una capa oculta) desde cero en Python. Implementa manualmente el algoritmo de retropropagación para actualizar los pesos de la red.  Utiliza esta red para entrenar un modelo que pueda clasificar puntos en dos clases basadas en su posición en un plano 2D. Genera datos sintéticos que sean linealmente separables.\n",
    "\n",
    "**Ejercicio 2:**  Comparación de funciones de activación\n",
    "\n",
    "Modifica la red del ejercicio 1 para probar diferentes funciones de activación (ReLU, sigmoidal, tanh) en la capa oculta.  Compara el rendimiento del entrenamiento con cada función de activación. Observa cómo cambia la rapidez de convergencia y si alguna configuración es particularmente propensa a problemas como el desvanecimiento o la explosión de gradientes.\n",
    "\n",
    "**Ejercicio 3:** Retropropagación con regularización\n",
    "\n",
    "Añade L2 (ridge) o L1 (lasso) regularización a la red neuronal que creaste en el ejercicio 1. Entrena la red en un conjunto de datos más complejo que introduzca algo de ruido y observa si la regularización ayuda a mejorar la generalización del modelo.\n",
    "\n",
    "**Ejercicio 4:** Experimentando con tamaños de batch\n",
    "\n",
    "Implementa la retropropagación utilizando diferentes tamaños de batch: desde el descenso de gradiente estocástico (un ejemplo a la vez) hasta el descenso de gradiente por lotes (usando todo el conjunto de datos a la vez). Analiza cómo cambian la estabilidad y la velocidad de convergencia del entrenamiento con los diferentes tamaños de batch. Considera incluir una visualización de la disminución de la pérdida a lo largo de las iteraciones para cada configuración de tamaño de batch.\n",
    "\n",
    "**Ejercicio 5:**  Optimización de Hiperparámetros\n",
    "\n",
    "Utiliza la red neuronal del ejercicio 1 y experimenta con diferentes tasas de aprendizaje y números de épocas de entrenamiento. Implementa una búsqueda de cuadrícula o aleatoria para encontrar la combinación óptima de tasa de aprendizaje y número de épocas. Evalúa el rendimiento del modelo en un conjunto de validación para determinar la mejor configuración de hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tus respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation Through Time (BPTT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intentaremos explicar BPTT, un algoritmo de retropropagación utilizado para entrenar redes neuronales recurrentes (RNN). Mostraremos la derivación matemática así como el código de implementación. Para el código, usaremos PyTorch para poder comparar los gradientes calculados automáticamente por PyTorch con los calculados manualmente. \n",
    "\n",
    "En primer lugar, definamos matemáticamente lo que hace una RNN en cada paso de tiempo $t$.\n",
    "\n",
    "Sea $x_t \\in \\mathbb{R}^{d_x}$ un vector de entrada en el paso de tiempo $t$. Una RNN de tamaño $d_h$ calcula su estado oculto $h_t$ como:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "  r_t &= U x_t + V h_{t-1} \\\\\n",
    "  h_t &= f \\left( r_t \\right)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "donde $U \\in \\mathbb{R}^{d_h \\times d_x}$ y $V \\in \\mathbb{R}^{d_h \\times d_h}$ son parámetros, y $f$ es una función de activación. Nota que no incluimos el término de sesgo aquí por simplicidad.\n",
    "\n",
    "Un vector de salida $y_t \\in \\mathbb{R}^{d_o}$ entonces puede ser calculado como:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "  s_t &= W h_t \\\\\n",
    "  y_t &= g \\left( s_t \\right)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "donde $W \\in \\mathbb{R}^{d_o \\times d_h}$ es un parámetro y $g$ es una función de salida no lineal, que depende de la tarea (por ejemplo, softmax para clasificación). Aquí también no incluimos el término de sesgo por simplicidad. Nota que $U$, $V$, y $W$ se comparten a lo largo de los pasos de tiempo, es decir, no hay matrices separadas para cada paso de tiempo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proceso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sea $L = \\mathcal{L}(y_t)$ la pérdida de nuestra RNN. Uno podría intentar derivar los gradientes de $U$, $V$, $W$ de manera ingenua. Por ejemplo, para calcular el gradiente sobre $W$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W_{ij}} = \\sum_k \\frac{\\partial L}{\\partial (s_t)_k} \\frac{\\partial (s_t)_k}{\\partial W_{ij}}\n",
    "$$\n",
    "\n",
    "Dado que\n",
    "\n",
    "$$\n",
    "\\frac{\\partial (s_t)_k}{\\partial W_{ij}} =\n",
    "\\begin{cases}\n",
    "0 & k \\neq i \\\\\n",
    "(h_t)_j & \\text{de lo contrario}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "tenemos\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W_{ij}} = \\frac{\\partial L}{\\partial (s_t)_i} (h_t)_j\n",
    "$$\n",
    "\n",
    "O, en notación matricial\n",
    "\n",
    "$$\n",
    "\\overline{W} = \\overline{s}_t h_t^{\\top}\n",
    "$$\n",
    "\n",
    "donde la notación de barra denota el gradiente de \\( L \\) con respecto a él, es decir, $\\overline{A}_{ij} = \\frac{\\partial L}{\\partial A_{ij}}$ y $\\overline{a}_i = \\frac{\\partial L}{\\partial a_i}$.\n",
    "\n",
    "Sin embargo, esto es **incorrecto**. Dado que $W$ se comparte a lo largo de los pasos de tiempo, contribuye a $s_t$ para *todos* los pasos de tiempo  $t$. Por lo tanto, al calcular el gradiente, necesitamos sumar los gradientes de todos los pasos de tiempo. En otras palabras, lo que necesitamos es:\n",
    "\n",
    "$$\n",
    "\\overline{W} = \\sum_t \\overline{s}_t h_t^{\\top}\n",
    "$$\n",
    "\n",
    "Los gradientes sobre $U$ y $V$ se pueden calcular de manera similar, es decir\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "  \\overline{U} &= \\sum_t \\overline{r}_t x_t^{\\top} \\\\\n",
    "  \\overline{V} &= \\sum_t \\overline{r}_t h_{t-1}^{\\top}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Ahora, los últimos gradientes. Gradiente sobre $r_t$ es\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "  \\frac{\\partial L}{\\partial (r_t)_i}\n",
    "  &= \\sum_j \\frac{\\partial L}{\\partial (h_t)_j} \\frac{\\partial (h_t)_j}{\\partial (r_t)_i} \\\\\n",
    "  &= \\frac{\\partial L}{\\partial (h_t)_i} f' (r_t)_i\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "O, en notación vectorial\n",
    "\n",
    "$$\n",
    "\\overline{r}_t = \\overline{h}_t * f' (r_t)\n",
    "$$\n",
    "\n",
    "De manera similar, el gradiente sobre $s_t$ se puede mostrar como $\\overline{s}_t = \\overline{y}_t * g' (s_t)$.\n",
    "\n",
    "Por último, necesitamos calcular $\\overline{h}_t$. Note que $h_t$ contribuye a $s_t$, y si $t$ no es el último paso de tiempo, entonces también contribuye a $r_{t+1}$. Por lo tanto, si $T$ denota el último paso de tiempo, entonces\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "  \\frac{\\partial L}{\\partial (h_T)_i}\n",
    "  &= \\sum_j \\frac{\\partial L}{\\partial (s_T)_j} \\frac{\\partial (s_T)_j}{\\partial (h_T)_i} \\\\\n",
    "  &= \\sum_j \\frac{\\partial L}{\\partial (s_T)_j} W_{ji}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "y para $t < T$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "  \\frac{\\partial L}{\\partial (h_t)_i}\n",
    "  &= \\sum_j \\frac{\\partial L}{\\partial (s_t)_j} \\frac{\\partial (s_t)_j}{\\partial (h_t)_i}\n",
    "  + \\sum_k \\frac{\\partial L}{\\partial (r_{t+1})_k} \\frac{\\partial (r_{t+1})_k}{\\partial (h_t)_i} \\\\\n",
    "  &= \\sum_j \\frac{\\partial L}{\\partial (s_t)_j} W_{ji}\n",
    "  + \\sum_k \\frac{\\partial L}{\\partial (r_{t+1})_k} V_{ki}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "En notación matricial (y combinando los dos)\n",
    "\n",
    "$$\n",
    "\\overline{h}_t = W^{\\top} \\overline{s}_t +\n",
    "\\begin{cases}\n",
    "0 & t = T \\\\\n",
    "V^{\\top} \\overline{r}_{t+1} & \\text{de lo contrario}\n",
    "\\end{cases}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así, los gradientes completos son\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "  \\overline{U} &= \\sum_t \\overline{r}_t x_t^{\\top} \\\\\n",
    "  \\overline{V} &= \\sum_t \\overline{r}_t h_{t-1}^{\\top} \\\\\n",
    "  \\overline{W} &= \\sum_t \\overline{s}_t h_t^{\\top} \\\\\n",
    "  \\overline{r}_t &= \\overline{h}_t * f' \\left( r_t \\right) \\\\\n",
    "  \\overline{s}_t &= \\overline{y}_t * g' \\left( s_t \\right) \\\\\n",
    "  \\overline{h}_t &= W^{\\top} \\overline{s}_t +\n",
    "    \\begin{cases}\n",
    "    0 & t = T \\\\\n",
    "    V^{\\top} \\overline{r}_{t+1} & \\text{de lo contrario}\n",
    "    \\end{cases}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementacion en PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La implementación del cálculo hacia adelante es bastante directa. Comenzamos desde el paso de tiempo 1, y calculamos $r_t$, $h_t$, $s_t$ y $y_t$, dados los inputs $x_t$ y $h_{t-1}$, hasta el último paso de tiempo $T$. Comenzamos desde el paso de tiempo 1 porque en la relación de recurrencia, para calcular $r_t$ necesitamos $h_{t-1}$. Por lo tanto, el paso de tiempo anterior debe completarse primero.\n",
    "\n",
    "La implementación del cálculo hacia atrás es similar, pero en cambio comenzamos desde el último paso de tiempo $T$ hasta el primero. Esto se debe a que en la relación de recurrencia, necesitamos $\\overline{r}_{t+1}$ para calcular $\\overline{h}_t$. Así, el siguiente paso de tiempo debe completarse de antemano. Además, a medida que iteramos, necesitamos acumular los gradientes en $U$, $V$ y $W$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, vamos a crear una clase RNNCell. Esta clase es responsable de un solo paso de tiempo. Tiene métodos forward y backward que realizan el cálculo hacia adelante y hacia atrás, respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNCell:\n",
    "    \"\"\"Una célula RNN responsable de un solo paso de tiempo.\n",
    "\n",
    "    Args:\n",
    "        inp_sz (int): Tamaño de la entrada.\n",
    "        hid_sz (int): Tamaño del estado oculto.\n",
    "        out_sz (int): Tamaño de la salida.\n",
    "    \"\"\"\n",
    "    def __init__(self, inp_sz, hid_sz, out_sz):\n",
    "        self.inp_sz = inp_sz\n",
    "        self.hid_sz = hid_sz\n",
    "        self.out_sz = out_sz\n",
    "\n",
    "        # U, V, W son los parámetros, por lo que establecemos requires_grad=True\n",
    "        # para indicar a PyTorch que necesitamos calcular los gradientes\n",
    "        self.U = torch.empty(hid_sz, inp_sz, requires_grad=True)\n",
    "        self.V = torch.empty(hid_sz, hid_sz, requires_grad=True)\n",
    "        self.W = torch.empty(out_sz, hid_sz, requires_grad=True)\n",
    "\n",
    "        # Estos son los gradientes en U, V y W que calcularemos\n",
    "        # manualmente. También los compararemos con\n",
    "        # los gradientes calculados por PyTorch para ver si nuestro\n",
    "        # cálculo de gradientes es correcto.\n",
    "        self.U_grad = torch.zeros_like(self.U)\n",
    "        self.V_grad = torch.zeros_like(self.V)\n",
    "        self.W_grad = torch.zeros_like(self.W)\n",
    "        \n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"Inicializar parámetros.\n",
    "\n",
    "        Los parámetros se inicializarán desde la distribución uniforme U(-0.1, 0.1).\n",
    "        \"\"\"\n",
    "        s = 0.1  # un valor mayor puede hacer que los gradientes exploten\n",
    "        torch.nn.init.uniform_(self.U, -s, s)\n",
    "        torch.nn.init.uniform_(self.V, -s, s)\n",
    "        torch.nn.init.uniform_(self.W, -s, s)\n",
    "    def zero_grad(self):\n",
    "        \"\"\"Se pone el gradiente a cero\"\"\"\n",
    "        self.U_grad.zero_()\n",
    "        self.V_grad.zero_()\n",
    "        self.W_grad.zero_()\n",
    "    \n",
    "    def forward(self, x, hp):\n",
    "        \"\"\"Realizar el cálculo hacia adelante.\n",
    "        \n",
    "        Args:\n",
    "            x (Tensor): Entrada en el paso de tiempo actual.\n",
    "            hp (Tensor): Estado oculto en el paso de tiempo anterior.\n",
    "            \n",
    "        Returns:\n",
    "            Tensor: Salida en el paso de tiempo actual.\n",
    "            Tensor: Estado oculto en el paso de tiempo actual.\n",
    "        \"\"\"\n",
    "        _, h, _, y = self._get_internals(x, hp)\n",
    "        return y, h\n",
    "\n",
    "    def backward(self, y_grad, rn_grad, x, hp):\n",
    "        \"\"\"Realizar el cálculo hacia atrás.\n",
    "        \n",
    "        Args:\n",
    "            y_grad (Tensor): Gradiente sobre la salida en el paso de tiempo actual.\n",
    "            rn_grad (Tensor): Gradiente sobre el vector r en el siguiente paso de tiempo.\n",
    "            x (Tensor): Entrada en el paso de tiempo actual que se pasó a `forward`.\n",
    "            hp (Tensor): Estado oculto en el paso de tiempo anterior que se pasó a `forward`.\n",
    "            \n",
    "        Returns:\n",
    "            Tensor: Gradiente sobre el vector r en el paso de tiempo actual.\n",
    "        \"\"\"\n",
    "        # Obtener los vectores internos r, h, y s del cálculo hacia adelante\n",
    "        r, h, s, _ = self._get_internals(x, hp)\n",
    "\n",
    "        s_grad = y_grad * torch.sigmoid(s) * (1-torch.sigmoid(s))\n",
    "        h_grad = self.W.t().matmul(s_grad) + self.V.t().matmul(rn_grad)\n",
    "        r_grad = h_grad * torch.sigmoid(r) * (1-torch.sigmoid(r))\n",
    "\n",
    "        # Los gradientes de los parámetros se acumulan\n",
    "        self.U_grad += r_grad.view(-1, 1).matmul(x.view(1, -1))\n",
    "        self.V_grad += r_grad.view(-1, 1).matmul(hp.view(1, -1))\n",
    "        self.W_grad += s_grad.view(-1, 1).matmul(h.view(1, -1))\n",
    "\n",
    "        return r_grad\n",
    "\n",
    "    def _get_internals(self, x, hp):\n",
    "        # Estos son los calculos forward reales\n",
    "        r = self.U.matmul(x) + self.V.matmul(hp)\n",
    "        h = torch.sigmoid(r)\n",
    "        s = self.W.matmul(h)\n",
    "        y = torch.sigmoid(s)\n",
    "        \n",
    "        return r, h, s, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, creemos una clase RNN. Esta clase acepta una RNNCell y es responsable de realizar la iteración sobre los pasos de tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    def __init__(self, cell):\n",
    "        self.cell = cell\n",
    "    \n",
    "    def forward(self, xs, h0):\n",
    "        \"\"\"Realiza la computación hacia adelante para todos los pasos de tiempo.\n",
    "        \n",
    "        Args:\n",
    "            xs (Tensor): Tensor 2-D de entradas para cada paso de tiempo. La\n",
    "                primera dimensión corresponde al número de pasos de tiempo.\n",
    "            h0 (Tensor): Estado oculto inicial.\n",
    "            \n",
    "        Returns:\n",
    "            Tensor: Tensor 2-D de salidas para cada paso de tiempo. La primera\n",
    "                dimensión corresponde al número de pasos de tiempo.\n",
    "            Tensor: Tensor 2-D de estados ocultos para cada paso de tiempo más\n",
    "                `h0`. La primera dimensión corresponde al número de pasos de\n",
    "                tiempo.\n",
    "        \"\"\"\n",
    "        ys, hs = [], [h0]  # Inicializa listas vacías para almacenar las salidas y los estados ocultos\n",
    "        for x in xs:\n",
    "            y, h = self.cell.forward(x, hs[-1])  # Calcula la salida y el siguiente estado oculto\n",
    "            ys.append(y)  # Agrega la salida a la lista de salidas\n",
    "            hs.append(h)  # Agrega el estado oculto al final de la lista de estados ocultos\n",
    "        return torch.stack(ys), torch.stack(hs)  # Apila las salidas y los estados ocultos en tensores\n",
    "    \n",
    "    def backward(self, ys_grad, xs, hs):\n",
    "        \"\"\"Realiza la computación hacia atrás para todos los pasos de tiempo.\n",
    "        \n",
    "        Args:\n",
    "            ys_grad (Tensor): Tensor 2-D de los gradientes en las salidas\n",
    "                para cada paso de tiempo. La primera dimensión corresponde a\n",
    "                el número de pasos de tiempo.\n",
    "            xs (Tensor): Tensor 2-D de entradas para cada paso de tiempo que\n",
    "                fue pasado a `forward`.\n",
    "            hs (Tensor): Tensor 2-D de estados ocultos que es devuelto por\n",
    "                `forward`.\n",
    "        \"\"\"\n",
    "        # Para el último paso de tiempo, el gradiente en r es cero\n",
    "        rn_grad = torch.zeros(self.cell.hid_sz)  # Inicializa el gradiente de la celda recurrente como cero\n",
    "\n",
    "        for y_grad, x, hp in reversed(list(zip(ys_grad, xs, hs))):\n",
    "            rn_grad = cell.backward(y_grad, rn_grad, x, hp)  # Calcula el gradiente para cada paso de tiempo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, la función de pérdida. Aquí utilizamos una pérdida simple de suma de cuadrados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(ys, ts):\n",
    "    return 0.5 * torch.sum((ys - ts)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, construimos nuestra RNN. Tendrá un tamaño de entrada de 2, un tamaño oculto de 3 y un tamaño de salida de 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = RNNCell(2, 4, 5)\n",
    "rnn = RNN(cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, creamos entradas y objetivos ficticios para nuestra RNN. Estableceremos el número de pasos de tiempo en 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = torch.rand(3, cell.inp_sz)\n",
    "hp = torch.rand(cell.hid_sz)\n",
    "ts = torch.rand(3, cell.out_sz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, realizamos la computación del forward y calculamos la pérdida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys, hs = rnn.forward(xs, hp)\n",
    "loss = compute_loss(ys, ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Veamos los gradientes calculados por PyTorch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.cell.U.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.cell.V.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.cell.W.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, ejecutemos nuestra computación backward y comparemos el resultado con el de PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esto se obtiene de nuestra función de pérdida de suma de cuadrados\n",
    "ys_grad = ys - ts\n",
    "\n",
    "with torch.no_grad():  # necesario para que PyTorch no genere un erro\n",
    "    rnn.cell.zero_grad()\n",
    "    rnn.backward(ys_grad, xs, hs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora veamos si nuestros gradientes calculados manualmente son correctos, es decir, si son iguales a los de PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.cell.U_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.cell.V_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.cell.W_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "¡Y son iguales! Así que nuestra computación es realmente correcta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicios\n",
    "\n",
    "**Ejercicio 1**: Derivación Manual de BPTT\n",
    "\n",
    "Dado un simple RNN con una capa oculta y una función de activación sigmoide, realiza la derivación manual de los gradientes para los parámetros $U$, $V$ y $W$ utilizando BPTT. Asume que la RNN tiene una sola unidad oculta y procesa secuencias de tres tiempos.\n",
    "\n",
    "**Ejercicio 2**: Implementación de BPTT desde cero\n",
    "\n",
    "Implementa una RNN simple en Python sin usar bibliotecas de deep learning como TensorFlow o PyTorch. Tu RNN debe incluir métodos de forward y backward, y debe ser capaz de procesar secuencias de longitud variable.\n",
    "\n",
    "**Ejercicio 3**: Comparación de gradientes\n",
    "\n",
    "Utiliza PyTorch para crear una RNN simple y compara los gradientes que calcula automáticamente con los que calculaste manualmente en el ejercicio 1 o implementaste en el ejercicio 2.\n",
    "\n",
    "**Ejercicio 4:** Exploración de la explosión y desvanecimiento de gradientes\n",
    "\n",
    "Modifica la RNN implementada en el ejercicio 2 para incluir secuencias de entrada de diferentes longitudes. Experimenta con inicializaciones de parámetros y observa cómo afectan a la magnitud de los gradientes durante el entrenamiento.\n",
    "\n",
    "**Ejercicio 5:** BPTT con diferentes funciones de activación\n",
    "\n",
    "Implementa varias funciones de activación (ReLU, tanh, sigmoide) en tu RNN del ejercicio 2. Entrena tu modelo en un conjunto de datos de prueba simple (puede ser generado sintéticamente) y compara cómo la elección de la función de activación afecta el rendimiento.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tus respuestas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
