# Actividades del curso de Procesamiento de Lenguaje Natural CC3S2

Repositorio que acompaña al curso CC0C2 Procesamiento de Lenguaje Natural

### Lista de proyectos

* Implementar desde cero mecanismos de atención dispersa (Sparse Attention), SliGLU, RMSNorm, MoE y Rope embedding en PyTorch.
* Ajustar finamente un LLM con PPO vs DPO vs ORPO utilizando el paquete PEFT.
* Entrenar un LLM de manera distribuida con el paquete Accelerate en AWS SageMaker utilizando la estrategia de optimización Zero Redundancy Optimizer.
* Construir un modelo autoregresivo que implemente una variante de atención secuencial con generación de texto paso a paso.
* Usar un LLM para generar imágenes a partir de descripciones textuales, integrando embeddings visuales y de texto.
* Optimizar el rendimiento del modelo mediante la búsqueda eficiente de hiperparámetros en un espacio complejo.
* Crear una aplicación interactiva de chat que utiliza GPT para responder en tiempo real, con soporte para WebSockets para comunicación continua.
* Entrenar y ajustar un LLM especializado en la clasificación de noticias por temas, usando técnicas de fine-tuning y transfer learning.
* Utilizar un Transformer entrenado en secuencias musicales para generar piezas musicales originales a partir de un tema o estilo dado.
* Usar embeddings contextuales para generar recomendaciones de películas basadas en descripciones de trama y preferencias del usuario.
* Desplegar una API de preguntas y respuestas basada en LLM finamente ajustado con búsqueda de documentos
* Utilizar Transformers para detectar anomalías en datos de series temporales, con aplicación en áreas como la monitorización de servidores o sistemas financieros.
* Optimizar un modelo BERT para dispositivos móviles con técnicas de pruning, quantization y knowledge distillation
* Implementar un GAN que pueda generar imágenes ajustando estilos específicos, usando un enfoque condicional en el generador.
* Crear una aplicación de resumen de documentos largos con un enfoque extractivo y abstractive en LLM
* Desarrollar un sistema de generación de diálogos no repetitivos en juegos usando GPT y RL (Reinforcement Learning)
* Crear un motor de búsqueda que pueda procesar consultas mixtas de texto e imágenes, devolviendo resultados relevantes de ambos tipos de medios.
* Ajustar finamente un LLM con datos médicos para tareas como clasificación de documentos clínicos o extracción de información específica.
* Crear un sistema de generación de texto condicional basado en estilos o temas específicos usando técnicas de control de generación en LLMs.
* Desplegar un servicio de generación automática de resúmenes de textos largos utilizando un LLM optimizado y microservicios en AWS Lambda.
* Ajustar finamente un modelo con QLoRA para aumentar el tamaño del contexto.
* Desplegar una API de aplicación LLM escalable con capacidades de streaming, KV-caching, batch continuo y generación de texto.
* Desplegar una aplicación RAG usando LangChain, FastAPI y LangServer
* Implementar desde cero mecanismos de atención multi-cabecera con variantes como la atención relacional y la atención local en PyTorch.
* Entrenar un modelo de lenguaje con técnicas de aprendizaje contrastivo para mejorar la comprensión de párrafos largos.
* Optimizar un modelo Transformer con técnicas de pruning y quantization para su despliegue en dispositivos edge.
* Desarrollar un sistema de recomendación utilizando modelos de lenguaje preentrenados en combinación con embeddings de usuarios y productos.
* Desplegar un chatbot de asistencia técnica utilizando un LLM finamente ajustado y Docker para su implementación en un entorno en la nube.
* Implementar un pipeline de procesamiento de lenguaje natural en tiempo real utilizando Apache Kafka y un modelo Transformer.
* Desarrollar un modelo de clasificación de sentimientos finamente ajustado con distilBERT en un entorno de producción utilizando TensorFlow Serving.
